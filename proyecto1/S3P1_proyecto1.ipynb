{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desasrrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/b8be43cf89c540bfaf3831f2c8506614)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto se usará el conjunto de datos de Car Listings de Kaggle, donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como: año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTrain_carListings.zip')\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTest_carListings.zip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del conjunto de test - acá se genera un número aleatorio como ejemplo\n",
    "np.random.seed(42)\n",
    "y_pred = pd.DataFrame(np.random.rand(dataTesting.shape[0]) * 75000 + 5000, index=dataTesting.index, columns=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "y_pred.to_csv('test_submission.csv', index_label='ID')\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos (10 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los datos de entrenamiento se dividen en datos de entrenamiento y validación. Si decidieron preprocesar los datos (estandarizar, normalizar, imputar valores, etc), estos son correctamente preprocesados al ajustar sobre los datos de entrenamiento (.fit_transform()) y al transformar los datos del set de validación (.transform()). (10 puntos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar las variables categóricas de dataTraing\n",
    "dataTraining[\"State\"], _ = pd.factorize(dataTraining[\"State\"])\n",
    "dataTraining[\"Make\"], _ = pd.factorize(dataTraining[\"Make\"])\n",
    "dataTraining[\"Model\"], _ = pd.factorize(dataTraining[\"Model\"])\n",
    "\n",
    "# Codificar las variables categóricas de dataTesting\n",
    "dataTesting[\"State\"], _ = pd.factorize(dataTesting[\"State\"])\n",
    "dataTesting[\"Make\"], _ = pd.factorize(dataTesting[\"Make\"])\n",
    "dataTesting[\"Model\"], _ = pd.factorize(dataTesting[\"Model\"])\n",
    "\n",
    "#dataTraining.head()\n",
    "dataTesting.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los valores de las variables en dataTraining\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "dataTraining.plot(kind = \"scatter\", x=\"Model\", y=\"Mileage\", c=\"Price\", colormap=\"jet\", xlim=(0, 25), ylim=(0, 250))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de las varibles predictoras\n",
    "Tr_feature_cols = dataTraining.columns[dataTraining.columns.str.startswith(\"C\")==False].drop(\"Price\")\n",
    "Tr_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Te_feature_cols = dataTesting.columns[dataTesting.columns.str.startswith(\"C\")==False]\n",
    "Te_feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Describir la variable Price\n",
    "dataTraining.Price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar las variables predictoras (X) y las varibles de interés (y)\n",
    "X_train = dataTraining[Tr_feature_cols]\n",
    "y_train = (dataTraining.Price > 18450).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dataTesting[Te_feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_train y y_train corresponde a los datos de las características y las etiquetas para el conjunto de entrenamiento\n",
    "# y X_test es el conjunto de características para el conjunto de validación.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "# Crear un objeto StandardScaler para el procesamiento de datos\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar X_train\n",
    "X_train_preprocessed = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar los datos de validación sin considerar ajustes en el modelo de datos\n",
    "X_val_preprocessed = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibración del modelo (15 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se calibran los parámetros que se consideren pertinentes del modelo de clasificación seleccionado. (5 puntos)\n",
    "- Se justifica el método seleccionado de calibración. (5 puntos)\n",
    "- Se analizan los valores calibrados de cada parámetro y se explica cómo afectan el modelo. (5 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Crear o definir el modelo RandomForest\n",
    "randomForest_model = RandomForestRegressor(random_state=42)\n",
    "randomForest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(randomForest_model, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el desempeño del modelo\n",
    "rf_performance = cross_val_score(randomForest_model, X_train, y_train, cv=10)\n",
    "rf_performance_values = pd.Series(rf_performance)\n",
    "print(rf_performance_values.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de lista de valores para iterar sobre diferentes valores de n_estimators\n",
    "estimator_range = range(10, 310, 10)\n",
    "\n",
    "# Definición de lista para almacenar la exactitud (accuracy) promedio para cada valor de n_estimators\n",
    "accuracy_scores = []\n",
    "\n",
    "# Uso de un 10-fold cross-validation para cada valor de n_estimators\n",
    "for estimator in estimator_range:\n",
    "    randomForest_model = RandomForestRegressor(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(randomForest_model, X_train, y_train, cv=10, scoring='accuracy').mean())\n",
    "print (accuracy_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica del desempeño del modelo vs la cantidad de n_estimators\n",
    "plt.plot(estimator_range, accuracy_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de lista de valores para iterar sobre diferentes valores de max_features\n",
    "feature_range = range(1, len(feature_cols)+1)\n",
    "\n",
    "# Definición de lista para almacenar la exactitud (accuracy) promedio para cada valor de max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# Uso de un 10-fold cross-validation para cada valor de max_features\n",
    "for feature in feature_range:\n",
    "    clf = RandomForestRegressor(n_estimators=200, max_features=feature, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(randomForest_model, X, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica del desempeño del modelo vs la cantidad de max_features\n",
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Definir el modelo XGBoost\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "print(xgb_model)\n",
    "\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda grid\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros encontrados:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento del modelo (15 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se entrena el modelo de clasificación escogido con los datos del set de entrenamiento preprocesados y los parámetros óptimos. (5 puntos)\n",
    "- Se presenta el desempeño del modelo en los datos de validación con al menos una métrica de desempeño. (5 puntos)\n",
    "- Se justifica la selección del modelo correctamente. (5 puntos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desarrollo del entregamiento del modelo Random Forest\n",
    "\n",
    "# Entrenar el modelo Random Forest utilizando los datos de entrenamiento\n",
    "randomForest_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = randomForest_model.predict(X_test)\n",
    "\n",
    "rf_predictions_df = pd.DataFrame(predictions, index=X_test.index, columns=['Price'])\n",
    "\n",
    "rf_predictions_df.to_csv('rf_test_submission.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo utilizando los datos de entrenamiento\n",
    "xgb_model = xgb.XGBRegressor(**best_params)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_predictions_df = pd.DataFrame(predictions, index=X_test.index, columns=['Price'])\n",
    "\n",
    "xgb_predictions_df.to_csv('xgb_test_submission.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disponibilizar modelo con Flask (30 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Para esta sección del notebook instale las siguientes librerías !pip install flask y !pip install flask_restplus.    Utilizamos pip install flask-restful.\n",
    "- Se disponibiliza el modelo en una API alojada en un servicio en la nube. (20 puntos)\n",
    "- Se hacen las predicciones sobre el valor del automóvil en al menos dos observaciones del set de validación. (10 puntos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "from flask import Flask\n",
    "from flask_restful import Api, Resource, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Desarrollo de la disponibilización del modelo\n",
    "\n",
    " Definición aplicación Flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Definición API Flask\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='API predicción precios vehículos',\n",
    "    description='API predicción precios vehículos')\n",
    "\n",
    "ns = api.namespace('predict', \n",
    "     description='Predicción precios vehículos')\n",
    "\n",
    "# Definición argumentos o parámetros de la API\n",
    "parser = api.parser()\n",
    "parser.add_argument(\n",
    "    'URL', \n",
    "    type=str, \n",
    "    required=True, \n",
    "    help='URL to be analyzed', \n",
    "    location='args')\n",
    "\n",
    "resource_fields = api.model('Resource', {\n",
    "    'result': fields.String,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la clase para disponibilización\n",
    "@ns.route('/')\n",
    "class vehiculosApi(Resource):\n",
    "\n",
    "    @api.doc(parser=parser)\n",
    "    @api.marshal_with(resource_fields)\n",
    "    def get(self):\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "        return {\n",
    "         \"result\": predict_proba(args['URL'])\n",
    "        }, 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de la aplicación que disponibiliza el modelo de manera local en el puerto 5000\n",
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones (10 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
