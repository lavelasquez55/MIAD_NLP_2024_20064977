{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcY9y56n86vn"
   },
   "source": [
    "# Tutorial: creación de ETLs con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gcg5UCbU86vp"
   },
   "source": [
    "## 1. Introducción\t\n",
    "    ¿Qué aprenderá?\n",
    "\tEn este tutorial aprenderá cómo puede utilizar PySpark para crear un proceso de ETL básico.\n",
    "\n",
    "\t¿Qué construirá?     \n",
    "        Construirá un ETL que toma los datos desde la base de datos transacional de WideWorldImporters (WWImportersTransactional), los transforma  a una representación cercana al análisis y los  almacena en la base de datos relacional WWImportersDWH.\n",
    "    \n",
    "\t¿Para qué?\n",
    "\tLa construcción de ETLs que se ajusten a modelos multidimensionales es un paso necesario dentro de un proceso de analìtica 1.0 , pues permite tomar los datos crudos de una fuente, generalmente transaccional, para transformarlos en datos limpios que puedan utilizarse para la toma de decisiones.\n",
    "    \n",
    "    ¿Qué necesita?\n",
    "    1. Python 3 con pip instalado\n",
    "    2. Jupyter notebook\n",
    "    3. Paquetes: Pyspark (3.0.1) y pandas (1.2.1)\n",
    "    4. Controlador Connector J de MySQL (ya se encuentra instalado)\n",
    "    5. Servidor SQL con base de datos relacional \"WWImportersTransactional\" y base de datos relacional que corresponde a la bodega de WWI \"Estudiante_i\"\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqQVz5s686vq"
   },
   "source": [
    "## 2. Proceso de ETL para una dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2UT2Ia586vr"
   },
   "source": [
    "En este proceso de ETL, se extraen los datos de las **órdenes de compra** de una base de datos transaccional y se almacenan en otra base de datos que corresponde a la bodega de datos, siguiendo una aproximación ROLAP. A continuación, se presenta el modelo multidimensional que es el modelo conceptual que representa el proceso de registro de órdenes de compra. Este modelo se utilizó para crear las tablas en la bodega de datos que representan el proceso de negocio y que serán cargadas como resultado del proceso ETL. \n",
    "\n",
    "Tenga en cuenta que las llaves ID_XXXX presentes en el modelo hacen referencia a las llaves de la bodega. Por otra parte, en el proceso de ETL se van a tener en cuenta las llaves transaccionales (**WWImportersTransactional**). La nomenclatura para utilizar es:\n",
    "\n",
    "1.   ID_XXXX_DWH, para las llaves de la bodega.\n",
    "2.   ID_XXXX_T, para las llaves transaccionales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpOSEfhX86vs"
   },
   "source": [
    "![Modelo ordenes](./WWI_modelo_ordenes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rg1M_rdU86vs"
   },
   "source": [
    "El proceso de ETL debe ser diseñado antes de implementarse. A partir de las conclusiones del entendimiento de datos sabemos las fuentes que se van a  utilizar y la relación entre las fuentes. Adicionalmente, se cuenta con las respuestas de la organización a las preguntas, resultado del entendimiento de datos. De esa manera sabemos cómo se deben manipular los datos. \n",
    "\n",
    "Este proceso de ETL lo dividimos en seis bloques, uno para cada dimensión o <i>tabla de hechos</i> del modelo, con la única excepción de la dimensión de fecha que, por ser una dimensión especial que se genera de forma independiente, no se incluye aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIa8WW1M86vt"
   },
   "source": [
    "![ETL](./Disenio_ETL.PNG)\n",
    "\n",
    "Recuerde que este es el diseño general. En el diseño completo se deben incluir las transformaciones realizadas a los datos a utilizarse en las dimensiones y tablas de hecho del modelo multidimensional, de acuerdo con lo que se muestra en la infografía de arquitectura de componentes (Componente proceso ETL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "os1iJYmu86vt"
   },
   "outputs": [],
   "source": [
    "# Configuración servidor base de datos transaccional\n",
    "# Recuerde usar Estudiante_i como usuario y la contraseña asigana en el excel de conexión a maquina virtual como contraseña\n",
    "db_user = 'Estudiante_24_202413'\n",
    "db_psswd = 'aabb1122'\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/WWImportersTransactional'\n",
    "\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/Estudiante_24_202413'\n",
    "\n",
    "# Driver de conexion\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HAGk_V1986vu"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace, to_date, dayofmonth, month, year, weekofyear, date_format, trim\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TQ3DM_Xf86vv",
    "outputId": "f2cdb157-a92d-4edc-a174-6f3bd09b9885"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\la.velasquez55\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Configuración de la sesión\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buA7s-vL86vw"
   },
   "source": [
    "### Conexión y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_QZ-j9q86vw"
   },
   "source": [
    "Se define la función para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mhy0jbh_86vw"
   },
   "outputs": [],
   "source": [
    "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhFsv4ba86vw"
   },
   "source": [
    "### BLOQUE 1\n",
    "Empezamos con el bloque 1: la dimensión <i>Empleado</i>, su fuente de datos viene de la tabla transaccional <i>Personas</i>. En la sentencia SQL filtramos usando WHERE para seleccionar solo las personas que sean vendedores y recuperamos únicamente los atributos que queremos, de acuerdo con  modelo dimensional. Recuerde que también puede usar el **.select()** de pyspark si no conoce los atributos de las tablas transaccionales. Sin embargo, es más eficiente aplicar el filtro en la consulta, ya que no trae a memoria más información de la necesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNKxFA-f86vx"
   },
   "source": [
    "#### Extracción\n",
    "A continuación, nos conectamos a la base de datos y extraemos la información deseada por medio de SQL, cargandola en un DataFrame PySpark, es decir en memoria. Note que aquí se pueden renombrar los atributos con la estructura <i>nombreActual AS nuevoNombre</i>. De la tabla de personas, En este paso, solo nos interesan los empleados, por lo cual se hace un filtro por medio del WHERE, buscando las personas cuyo atributo EsVendedor sea igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IopBNYuc86vx",
    "outputId": "0589f8a9-527e-4b28-d096-a176efd48e97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+----------+\n",
      "|ID_Empleado|            Nombre|EsVendedor|\n",
      "+-----------+------------------+----------+\n",
      "|          2|    Kayla Woodcock|      true|\n",
      "|          3|     Hudson Onslow|      true|\n",
      "|          6|     Sophia Hinton|      true|\n",
      "|          7|         Amy Trefl|      true|\n",
      "|          8|    Anthony Grosse|      true|\n",
      "|         13|Hudson Hollinworth|      true|\n",
      "|         14|         Lily Code|      true|\n",
      "|         15|         Taj Shand|      true|\n",
      "|         16|     Archer Lamble|      true|\n",
      "|         20|       Jack Potter|      true|\n",
      "+-----------+------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_empleados = '''(SELECT DISTINCT ID_persona AS ID_Empleado, NombreCompleto AS Nombre, EsVendedor FROM WWImportersTransactional.Personas WHERE EsVendedor=1) AS Temp_empleados'''\n",
    "empleados = obtener_dataframe_de_bd(source_db_connection_string, sql_empleados, db_user, db_psswd)\n",
    "empleados.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vtE61qk986vx"
   },
   "source": [
    "#### Transformación\n",
    "Recuerde que, puede hacer uso de selectExpr, filter, where entre otras de PySpark para modificar los datos cargados. Por ejemplo, el siguiente código utiliza <i>selectExpr</i> para renombrar la columna ID_Empleado por ID_Empleado_T, esta es la convención que vamos a utilizar: \"_T\" para indicar que el ID es el que estaba en la base de datos transaccional y \"_DWH\" para indicar que son ID's propios de la bodega. Usamos withColumn y monotonicallu_increasing_id para crear un ID acumulativo para cada registro en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------+\n",
      "|ID_Empleado_DWH|ID_Empleado_T|        Nombre|\n",
      "+---------------+-------------+--------------+\n",
      "|              1|            2|Kayla Woodcock|\n",
      "|              2|            3| Hudson Onslow|\n",
      "|              3|            6| Sophia Hinton|\n",
      "|              4|            7|     Amy Trefl|\n",
      "|              5|            8|Anthony Grosse|\n",
      "+---------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "empleados = empleados.selectExpr('ID_Empleado as ID_Empleado_T','Nombre')\n",
    "empleados = empleados.coalesce(1).withColumn('ID_Empleado_DWH', f.monotonically_increasing_id() + 1)\n",
    "empleados = empleados.select('ID_Empleado_DWH','ID_Empleado_T','Nombre')\n",
    "empleados.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Oou0g986vy"
   },
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qICUWYCa86vy"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, empleados,'Empleado', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6k37LtO86vy"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvj5E1GS86vz"
   },
   "source": [
    "### BLOQUE 2\n",
    "Empezamos el bloque 2: dimensión ciudad. Su fuente de datos es una combinación de las tablas transaccionales <i>paises, provinciasEstados y ciudades</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5kFkHTD86vz"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FEW2mcMn86vz",
    "outputId": "a18be86c-fd81-4b56-de5c-bec1f41db118"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_ciudad_T', 'NombreCiudad', 'ID_EstadoProvincia', 'Poblacion'] ['ID_Pais', 'Nombre', 'Continente', 'Region', 'Subregion'] ['ID_EstadoProvincia', 'NombreEstadoProvincia', 'TerritorioVentas', 'ID_Pais']\n"
     ]
    }
   ],
   "source": [
    "#EXTRACCION\n",
    "sql_paises = '''(SELECT DISTINCT ID_Pais, Nombre, Continente, Region, Subregion FROM WWImportersTransactional.Paises) AS Temp_paises'''\n",
    "sql_provincias_estados = '''(SELECT DISTINCT ID_EstadosProvincias AS ID_EstadoProvincia, NombreEstadoProvincia, TerritorioVentas, ID_Pais FROM WWImportersTransactional.EstadosProvincias) AS Temp_estados_provincias'''\n",
    "sql_ciudades = '''(SELECT DISTINCT ID_ciudad as ID_ciudad_T, NombreCiudad, ID_EstadoProvincia, Poblacion FROM WWImportersTransactional.Ciudades) AS Temp_ciudades'''\n",
    "\n",
    "paises = obtener_dataframe_de_bd(source_db_connection_string, sql_paises, db_user, db_psswd)\n",
    "provincias_estados = obtener_dataframe_de_bd(source_db_connection_string, sql_provincias_estados, db_user, db_psswd)\n",
    "ciudades = obtener_dataframe_de_bd(source_db_connection_string, sql_ciudades, db_user, db_psswd)\n",
    "\n",
    "print(ciudades.columns, paises.columns, provincias_estados.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddFhEOmL86vz"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8un2p4so86v0",
    "outputId": "ba2758d9-aca3-4198-c13c-514bdbf51061"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "|ID_Ciudad_DWH|ID_ciudad_T|NombreCiudad|   Continente|         Pais|Poblacion|  Region|TerritorioVentas|NombreEstadoProvincia|       Subregion|\n",
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "|            1|         49|     Absecon|North America|United States|     8411|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            2|        150|    Adelphia|North America|United States|     NULL|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            3|        336|      Albion|North America|United States|     NULL|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            4|        458|   Allamuchy|North America|United States|       78|Americas|         Mideast|           New Jersey|Northern America|\n",
      "|            5|        480|   Allendale|North America|United States|     6505|Americas|         Mideast|           New Jersey|Northern America|\n",
      "+-------------+-----------+------------+-------------+-------------+---------+--------+----------------+---------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "ciudades = ciudades.join(provincias_estados, how = 'left', on = 'ID_EstadoProvincia')\n",
    "ciudades = ciudades.join(paises, how = 'left', on = 'ID_Pais')\n",
    "ciudades = ciudades.coalesce(1).withColumn('ID_Ciudad_DWH', f.monotonically_increasing_id() + 1)\n",
    "ciudades = ciudades.select('ID_Ciudad_DWH','ID_ciudad_T','NombreCiudad','Continente','Nombre','Poblacion',\n",
    "                          'Region','TerritorioVentas','NombreEstadoProvincia','Subregion') \\\n",
    "                    .withColumnRenamed('Nombre','Pais')\n",
    "ciudades.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuvVgJ4R86v0"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "yCC2zZqY86v0"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, ciudades,'Ciudad', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fo-J97586v0"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HpgwA6t86v0"
   },
   "source": [
    "### BLOQUE 3\n",
    "Bloque 3: dimensión paquete. Su fuente de datos es la tabla transaccional <i>Paquetes</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjDeVYd86v1"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "2HTzU96W86v1"
   },
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_paquetes = '''(SELECT DISTINCT ID_TipoPaquete AS ID_TipoPaquete_T, TipoPaquete AS Nombre FROM WWImportersTransactional.Paquetes) AS Temp_Paquetes'''\n",
    "paquetes = obtener_dataframe_de_bd(source_db_connection_string, sql_paquetes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7xbgfCk86v1"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "97vmyl3Q86v1",
    "outputId": "0ffd3364-9b73-4001-e9bf-de53c97a2b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------+\n",
      "|ID_TipoPaquete_DWH|ID_TipoPaquete_T|Nombre|\n",
      "+------------------+----------------+------+\n",
      "|                 1|               1|   Bag|\n",
      "|                 2|               2| Block|\n",
      "|                 3|               3|Bottle|\n",
      "|                 4|               4|   Box|\n",
      "|                 5|               5|   Can|\n",
      "+------------------+----------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "paquetes = paquetes.coalesce(1).withColumn('ID_TipoPaquete_DWH', f.monotonically_increasing_id() + 1)\n",
    "paquetes = paquetes.select('ID_TipoPaquete_DWH','ID_TipoPaquete_T','Nombre')\n",
    "paquetes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rh_102Yy86v1"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UpbxgpWn86v1"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, paquetes,'TipoPaquete', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTy1oE3V86v2"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYetZ2Ip86v2"
   },
   "source": [
    "### BLOQUE 4\n",
    "Bloque 4: dimensión producto, su fuente de datos es la combinación entre las tablas transaccionales Productos y Colores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HogvCqW_86v2"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZEJjQslF86v2"
   },
   "outputs": [],
   "source": [
    "sql_productos = '''(SELECT DISTINCT ID_Producto as ID_Producto_T, ID_Color, NombreProducto, Marca, Necesita_refrigeracion, Dias_tiempo_entrega, Impuesto, PrecioUnitario, PrecioRecomendado FROM WWImportersTransactional.Producto) AS Temp_productos'''\n",
    "sql_colores = '''(SELECT DISTINCT ID_Color, Color FROM WWImportersTransactional.Colores) AS Temp_colores'''\n",
    "\n",
    "productos = obtener_dataframe_de_bd(source_db_connection_string, sql_productos, db_user, db_psswd)\n",
    "colores = obtener_dataframe_de_bd(source_db_connection_string, sql_colores, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rKmT9jd86v2"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "petU8G6K86v2",
    "outputId": "34d83d0f-f557-4ded-b71e-52afb08dfaf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+--------------------+---------+-----+----------------------+-------------------+-----------------+--------+--------------+\n",
      "|ID_Producto_DWH|ID_Producto_T|      NombreProducto|    Marca|Color|Necesita_refrigeracion|Dias_tiempo_entrega|PrecioRecomendado|Impuesto|PrecioUnitario|\n",
      "+---------------+-------------+--------------------+---------+-----+----------------------+-------------------+-----------------+--------+--------------+\n",
      "|              1|           59|RC toy sedan car ...|Northwind|  Red|                     0|                 14|               37|      15|            25|\n",
      "|              2|           64|RC vintage Americ...|Northwind|  Red|                     0|                 14|               45|      15|            30|\n",
      "|              3|           68|Ride on toy sedan...|Northwind|  Red|                     0|                 14|              344|      15|           230|\n",
      "|              4|           73|Ride on vintage A...|Northwind|  Red|                     0|                 14|              426|      15|           285|\n",
      "|              5|          176|Bubblewrap dispen...|     NULL|  Red|                     0|                 14|              359|      15|           240|\n",
      "+---------------+-------------+--------------------+---------+-----+----------------------+-------------------+-----------------+--------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "productos = productos.join(colores, how = 'left', on = 'ID_Color').fillna({'Color': 'Missing'})\n",
    "productos = productos.coalesce(1).withColumn('ID_Producto_DWH', f.monotonically_increasing_id() + 1)\n",
    "productos = productos.select('ID_Producto_DWH','ID_Producto_T','NombreProducto','Marca','Color','Necesita_refrigeracion','Dias_tiempo_entrega','PrecioRecomendado','Impuesto','PrecioUnitario')\n",
    "productos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9SnkMUH86v3"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "MMArotXz86v3"
   },
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, productos,'Producto', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YglraEoA86v3"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UM4L4jA086v3"
   },
   "source": [
    "### BLOQUE 5\n",
    "Bloque 5: dimensión cliente. Su fuente de datos es la combinación entre las tablas transaccionales Categorias de cliente, Grupos de compra y Clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8O1GvOd86v3"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "znROuHS086v3"
   },
   "outputs": [],
   "source": [
    "sql_categoriasCliente = '''(SELECT DISTINCT ID_Categoria, NombreCategoria FROM WWImportersTransactional.CategoriasCliente) AS Temp_categoriasclientes'''\n",
    "sql_gruposCompra = '''(SELECT DISTINCT ID_GrupoCompra, NombreGrupoCompra FROM WWImportersTransactional.GruposCompra) AS Temp_gruposcompra'''\n",
    "sql_clientes = '''(SELECT DISTINCT ID_Cliente as ID_Cliente_T, Nombre, ClienteFactura, ID_Categoria, ID_GrupoCompra, ID_CiudadEntrega, LimiteCredito, FechaAperturaCuenta, DiasPago FROM WWImportersTransactional.Clientes) AS Temp_clientes'''\n",
    "\n",
    "categoriasCliente = obtener_dataframe_de_bd(source_db_connection_string, sql_categoriasCliente, db_user, db_psswd)\n",
    "gruposCompra = obtener_dataframe_de_bd(source_db_connection_string, sql_gruposCompra, db_user, db_psswd)\n",
    "clientes = obtener_dataframe_de_bd(source_db_connection_string, sql_clientes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mo633Vpg86v3"
   },
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "wwK8bV8Z86v3",
    "outputId": "7b494261-1640-4108-98f8-65fbe04c7b91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|              Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             1|         801|         Eric Torres|      Corporate|          Missing|           801|           31321|         3000|2013-01-01 00:00:00|       7|\n",
      "|             2|         802|        Cosmina Vlad|      Corporate|          Missing|           802|            5192|         2940|2013-01-01 00:00:00|       7|\n",
      "|             3|         803|          Bala Dixit|   Novelty Shop|          Missing|           803|           33799|         2000|2013-01-01 00:00:00|       7|\n",
      "|             4|         804|Aleksandrs Riekstins| Computer Store|          Missing|           804|           18069|         2200|2013-01-01 00:00:00|       7|\n",
      "|             5|         805|        Ratan Poddar|   Novelty Shop|          Missing|           805|           10194|         3300|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION \n",
    "# EL SUPUESTO QUE SE TIENE ES QUE TODOS LOS CLIENTES TIENEN TODOS SUS DATOS DE CATEGORIA Y GRUPO Y NO SE ESTÁN PERDIENDO CLIENTES AL REALIZAR ESTE JOIN\n",
    "clientes = clientes.join(gruposCompra, how = 'left', on = 'ID_GrupoCompra')\n",
    "clientes = clientes.alias('cl').join(categoriasCliente.alias('ct'), how = 'left', on = 'ID_Categoria') \\\n",
    ".select([col('cl.ID_Cliente_T'),col('cl.Nombre'),col('ct.NombreCategoria'),col('cl.NombreGrupoCompra') \\\n",
    "        ,col('cl.ClienteFactura'),col('cl.ID_CiudadEntrega'),col('cl.LimiteCredito'),col('cl.FechaAperturaCuenta'),col('cl.DiasPago')])\n",
    "clientes = clientes.coalesce(1).withColumn('ID_Cliente_DWH', f.monotonically_increasing_id() + 1)\n",
    "clientes = clientes.select('ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
    "                          'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago')\n",
    "\n",
    "clientes = clientes.fillna({'NombreCategoria':'Missing','NombreGrupoCompra':'Missing'})\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T| Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             0|            |Missing|        Missing|          Missing|             0|               0|             |                   |        |\n",
      "+--------------+------------+-------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Crea el registro para el id = 0\n",
    "clientes_0 = [('0','','Missing','Missing','Missing','0','0','','','')]\n",
    "columns = ['ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
    "            'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago']\n",
    "cliente_0 = spark.createDataFrame(data=clientes_0,schema=columns)\n",
    "cliente_0.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|              Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             1|         801|         Eric Torres|      Corporate|          Missing|           801|           31321|         3000|2013-01-01 00:00:00|       7|\n",
      "|             2|         802|        Cosmina Vlad|      Corporate|          Missing|           802|            5192|         2940|2013-01-01 00:00:00|       7|\n",
      "|             3|         803|          Bala Dixit|   Novelty Shop|          Missing|           803|           33799|         2000|2013-01-01 00:00:00|       7|\n",
      "|             4|         804|Aleksandrs Riekstins| Computer Store|          Missing|           804|           18069|         2200|2013-01-01 00:00:00|       7|\n",
      "|             5|         805|        Ratan Poddar|   Novelty Shop|          Missing|           805|           10194|         3300|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clientes = clientes.union(cliente_0)\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|ID_Cliente_DWH|ID_Cliente_T|              Nombre|NombreCategoria|NombreGrupoCompra|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "|             0|            |             Missing|        Missing|          Missing|             0|               0|             |                   |        |\n",
      "|             1|         801|         Eric Torres|      Corporate|          Missing|           801|           31321|         3000|2013-01-01 00:00:00|       7|\n",
      "|             2|         802|        Cosmina Vlad|      Corporate|          Missing|           802|            5192|         2940|2013-01-01 00:00:00|       7|\n",
      "|             3|         803|          Bala Dixit|   Novelty Shop|          Missing|           803|           33799|         2000|2013-01-01 00:00:00|       7|\n",
      "|             4|         804|Aleksandrs Riekstins| Computer Store|          Missing|           804|           18069|         2200|2013-01-01 00:00:00|       7|\n",
      "+--------------+------------+--------------------+---------------+-----------------+--------------+----------------+-------------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se ordena por el identificador DWH\n",
    "clientes = clientes.withColumn('ID_Cliente_DWH',col('ID_Cliente_DWH').cast('int')).orderBy(col('ID_Cliente_DWH'))\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i36NawhX86v4"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "QcvMzmCf86v4"
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column NombreGrupoCompra not found in schema Some(StructType(StructField(ID_Cliente_DWH,IntegerType,false),StructField(ID_Cliente_T,IntegerType,true),StructField(Nombre,StringType,true),StructField(ClienteFactura,StringType,true),StructField(ID_CiudadEntrega_DWH,StringType,true),StructField(LimiteCredito,IntegerType,true),StructField(FechaAperturaCuenta,DateType,true),StructField(DiasPago,IntegerType,true),StructField(NombreGrupoCuenta,StringType,true),StructField(NombreCategoria,StringType,true))).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# CARGUE\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mguardar_db\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdest_db_connection_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclientes\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCliente\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_user\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_psswd\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mguardar_db\u001b[1;34m(db_connection_string, df, tabla, db_user, db_psswd)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mguardar_db\u001b[39m(db_connection_string, df, tabla, db_user, db_psswd):\n\u001b[0;32m     15\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_connection_string\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdbtable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabla\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_user\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_psswd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcom.mysql.cj.jdbc.Driver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m---> 22\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[1;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: Column NombreGrupoCompra not found in schema Some(StructType(StructField(ID_Cliente_DWH,IntegerType,false),StructField(ID_Cliente_T,IntegerType,true),StructField(Nombre,StringType,true),StructField(ClienteFactura,StringType,true),StructField(ID_CiudadEntrega_DWH,StringType,true),StructField(LimiteCredito,IntegerType,true),StructField(FechaAperturaCuenta,DateType,true),StructField(DiasPago,IntegerType,true),StructField(NombreGrupoCuenta,StringType,true),StructField(NombreCategoria,StringType,true)))."
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string,clientes,'Cliente', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMyvdEB-86v4"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ocmdLWv86v4"
   },
   "source": [
    "### BLOQUE 6\n",
    "Bloque 6: Hecho orden. Su fuente de datos es la combinación entre las tablas transaccionales Ordenes y detalles de orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvgnsPfK86v4"
   },
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9b4Qs9_886v4"
   },
   "outputs": [],
   "source": [
    "sql_ordenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.Ordenes) AS Temp_ordenes'''\n",
    "sql_detallesOrdenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.DetallesOrdenes) AS Temp_detallesordenes'''\n",
    "ordenes = obtener_dataframe_de_bd(source_db_connection_string, sql_ordenes, db_user, db_psswd)\n",
    "detallesOrdenes = obtener_dataframe_de_bd(source_db_connection_string, sql_detallesOrdenes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTv_CIOT86v5"
   },
   "source": [
    "#### Transformación\n",
    "Estas son las respuestas de Wide World Importers a los conclusiones obtenidas en el entendimiento de los datos:\n",
    "- La regla de negocio \"La tasa de impuesto es de 10% o 15%\" es correcta, pero habian errores en la tabla original, que fueron corregidos. \n",
    "- Para la segunda regla de negocio: \"Son 73.595 órdenes detalladas en 231.412 lineas de detalle de órdenes realizadas desde 2013\", si faltaban datos, los cuales fueron completados, y nos dicen que en cuanto a consistencia ellos revisaron las tablas e hicieron correcciones, pero que los duplicados completos de ordenes los eliminemos\n",
    "- \"El formato de fechas manejado es YYYY-MM-DD HH:MM:SS si tienen hora, minutos y segundos. De lo contrario el formato es YYYY-MM-DD\": En cuanto a formatos de fechas estan de acuerdo con que los estandarizemos y el formato sea el especificado en la regla\n",
    "- Para las descripciones de productos que eran \"a\", se actualizaron a los valores reales. \n",
    "- Se pueden eliminar las columnas Comenarios, Instrucciones_de_entrega y comentarios_internos porque estan vacias. \n",
    "- A pesar de estar en un proceso de mejorar la calidad de los datos y mantener los nulos nos ayudaría a reflejar esa calidad, de la mano con el grupo de analitica de WWI se decide imputar por la media el valor extremo de la variable Cantidad\n",
    "- Para las ordenes las columnas Seleccionado_por_ID_de_persona, ID_de_pedido_pendiente, Seleccion_completada_cuando, y para las columnas Seleccion_completada_cuando de la tabla detalles de ordenes, se decide mantener los valores vacíos, sin embargo para la variable Precio_unitario el negocio reviso y complemento los valores faltantes\n",
    "\n",
    "Las tablas usadas en el tutorial de entendimiento de datos estaran disponibles para su revision con los siguientes nombres: OrdenesCopia y DetallesOrdenesCopia. \n",
    "\n",
    "Para este tutorial vamos a trabajar con unas tablas que dadas las conclusiones del tutorial de entendimiento, WWImporters revisó los datos originales, creo tablas y las llamo \"Ordenes\" y \"DetallesOrdenes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcHdgPzj86v5"
   },
   "source": [
    "Se hace una verificación de los valores de la tasa de impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT5i7Yjq86v5",
    "outputId": "95819129-618e-4d35-dd6b-878ea1f88ce8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select(\"Tasa_de_impuesto\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI27nmvB86v5"
   },
   "source": [
    "Se hace una verificación del rango de fechas disponible en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0GmNF6x86v5",
    "outputId": "326502fa-449d-47e3-faa5-ecd2fb34651b"
   },
   "outputs": [],
   "source": [
    "ordenes.agg({\"Fecha_de_pedido\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAp83aSn86v6"
   },
   "source": [
    "Se elimina columnas Comenarios, Instrucciones_de_entrega y comentarios_internos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX2Wl4zo86v6"
   },
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop(*[\"Comentarios\", \"Instrucciones_de_entrega\",\"comentarios_internos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfONrMtq86v6"
   },
   "source": [
    "Se eliminan duplicados totales de ordenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3KbTJ4k86v6",
    "outputId": "e0783886-2dde-4a7f-f031-72d442ba87ba"
   },
   "outputs": [],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocWjOSPD86v6"
   },
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qF5L6I186v6",
    "outputId": "e2e4a3b4-025b-41b0-e7da-057df910b082"
   },
   "outputs": [],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqSCkt_V86v6"
   },
   "source": [
    "Se hace verificación de consistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXNKhNV986v7",
    "outputId": "2b6014c8-837e-4fc5-f98b-973e8899ac0f"
   },
   "outputs": [],
   "source": [
    "#consistencia: revisar genially: definicion de consistencia\n",
    "ids_ordenes = set([x.ID_de_pedido for x in ordenes.select('ID_de_pedido').collect()])\n",
    "ids_detalles = set([x.ID_de_pedido for x in detallesOrdenes.select('ID_de_pedido').collect()])\n",
    "\n",
    "len(ids_ordenes-ids_detalles), len(ids_detalles-ids_ordenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB8BrURo86v7"
   },
   "source": [
    "En el siguiente código para el manejo de fechas, pasamos del formato MM dd,YYYY al formato establecido en la regla de negocio<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ajB_7vTr86v7",
    "outputId": "9cabe64a-58b5-472a-9fce-0eeedfcdb0d6"
   },
   "outputs": [],
   "source": [
    "# TRANSFORMACION\n",
    "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
    "cumplenFormato = ordenes.filter(ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "noCumplenFormato = ordenes.filter(~ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "print(noCumplenFormato.count(), cumplenFormato.count())\n",
    "print(noCumplenFormato.show(5))\n",
    "noCumplenFormato = noCumplenFormato.withColumn('Fecha_de_pedido', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d'), t.StringType())(f.col('Fecha_de_pedido')))\n",
    "ordenes = noCumplenFormato.union(cumplenFormato)\n",
    "noCumplenFormato.count(), ordenes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN-fsV5_86v7"
   },
   "source": [
    "Descripciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8lPrvq2m86v7",
    "outputId": "5eb1f4eb-5b44-4753-d094-ba16ad225fd7"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.where(length(col(\"Descripcion\")) <= 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a31mBQwD86v7"
   },
   "source": [
    "Imputar valor maximo de cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAeVZ5Xc86v8",
    "outputId": "6a8395e8-cdeb-44b7-a58d-1428b6682823"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEM7tcJ986v8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes = detallesOrdenes.replace( 10000000, 360, 'Cantidad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmteyIwh86v8",
    "outputId": "79f8b8d0-b28a-42b4-c9bb-6c3eae3f537f"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uda-rfmr86v8"
   },
   "outputs": [],
   "source": [
    "detallesOrdenes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOcOg5wJ86v8"
   },
   "outputs": [],
   "source": [
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRyB9egF86v8"
   },
   "source": [
    "Se unen los dos dataframes en un nuevo dataframe, se verifica que no haya duplicados y si los hay se eliminan. Se crea un nuevo dataframe que va a tener toda la información del hecho orden transformada y lista para continuar el proceso de cargue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RVZ_KIj86v8",
    "outputId": "90b92db0-5f18-44a1-a14a-73ab6e1ce8f5"
   },
   "outputs": [],
   "source": [
    "ordenes_tmp =ordenes\n",
    "ordenes_tmp = ordenes_tmp.join(detallesOrdenes, how = 'inner', on = 'ID_de_pedido')\n",
    "ordenes_tmp = ordenes_tmp.withColumn('Valor_total',col('Precio_unitario')*col('Cantidad'))\n",
    "ordenes_tmp = ordenes_tmp.withColumn('Impuestos',col('Valor_total')*col('Tasa_de_impuesto'))\n",
    "ordenes_tmp = ordenes_tmp.selectExpr('ID_de_pedido as ID_de_pedido_T','ID_Producto','Fecha_de_pedido','ID_de_cliente','ID_de_vendedor','ID_Tipo_Paquete','Cantidad','Valor_total', 'Impuestos')\n",
    "\n",
    "print((ordenes_tmp.count(),ordenes_tmp.distinct().count()))\n",
    "\n",
    "ordenes_tmp = ordenes_tmp.drop_duplicates()\n",
    "ordenes_tmp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, ordenes_tmp,'Hecho_Orden_Tmp', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree la tabla de Fecha según el material compartido y adicione el left join al crear la tabla de ordenes para que quede completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El idPedido representa la dimensión degenerada Pedido\n",
    "# Si hay campos nulos en ordenes_tmp al hacer join por el left outer join no se perderan y se utiliza como comodín un id=0 que debe existir en todas las dimensiones.\n",
    "# Ese comodín representa el registro sin Dato.\n",
    "# Debe adicionarle a todas las tablas el registro con identificador 0, como se muestra para la tabla de clientes\n",
    "# Recuerde que falta incluir el join con la tabla de Fecha para que la tabla quede completa.\n",
    "\n",
    "ordenes = ordenes_tmp.alias('o').join(clientes.alias('cl'), ordenes_tmp.ID_de_cliente == clientes.ID_Cliente_T,'left')\\\n",
    "                    .join(ciudades.alias('ciu'), clientes.ID_CiudadEntrega == ciudades.ID_ciudad_T,'left') \\\n",
    "                    .join(empleados.alias('e'), ordenes_tmp.ID_de_vendedor == empleados.ID_Empleado_T,'left') \\\n",
    "                    .join(paquetes.alias('p'), ordenes_tmp.ID_Tipo_Paquete == paquetes.ID_TipoPaquete_T,'left') \\\n",
    "                    .join(productos.alias('pr'), (ordenes_tmp.ID_Producto == productos.ID_Producto_T) ,'left') \\\n",
    "                    .select([col('o.ID_de_pedido_T'),col('cl.ID_Cliente_DWH'),col('ciu.ID_Ciudad_DWH'),\n",
    "                             col('e.ID_Empleado_DWH'),col('pr.ID_Producto_DWH'),col('p.ID_TipoPaquete_DWH'),\n",
    "                             col('o.Cantidad'),col('o.Valor_total'),col('o.Impuestos')]) \\\n",
    "                    .fillna({'ID_Cliente_DWH': 0, 'ID_Ciudad_DWH': 0, 'ID_Empleado_DWH': 0, 'ID_Producto_DWH': 0,\n",
    "                             'ID_TipoPaquete_DWH': 0})\n",
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes = ordenes.select('ID_de_pedido_T','ID_Ciudad_DWH','ID_Cliente_DWH','ID_Empleado_DWH','ID_Producto_DWH',\n",
    "                         'ID_TipoPaquete_DWH','Cantidad','Impuestos','Valor_total') \\\n",
    "                    .withColumnRenamed('Valor_total','Total')\n",
    "ordenes.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9f10qpB86v9"
   },
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, ordenes,'Hecho_Orden', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXk0Fxmu86v9"
   },
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWmcDXue86v9"
   },
   "source": [
    "# Resultado de consultas\n",
    "Corresponde a las consultas realizadas sobre las tablas, para mostrar el estado final de las tablas pobladas como resultado del proceso de ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGMlLaje86v9"
   },
   "source": [
    "# 3. Tarea ETL\n",
    "Espacio para desarrollar la tarea planteada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwyeLpt386v9"
   },
   "source": [
    "## Dimensión Proveedor\n",
    "La fuente de datos es la combinación entre las tablas transaccionales Proveedores, CategoriasProveedores y Personas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_proveedores = '''(SELECT DISTINCT ProveedorID AS ID_Proveedor_T, NombreProveedor AS Nombre, CategoriaProveedorID, PersonaContactoPrincipalID, DiasPago AS Dias_pago, CodigoPostal AS Codigo_postal FROM WWImportersTransactional.proveedores) AS Temp_Proveedores'''\n",
    "sql_categoriasProveedores = '''(SELECT DISTINCT * FROM WWImportersTransactional.CategoriasProveedores) AS Temp_CategoriasProveedores'''\n",
    "sql_personas = '''(SELECT DISTINCT ID_persona, NombreCompleto FROM WWImportersTransactional.Personas) AS Temp_Personas'''\n",
    "\n",
    "proveedores = obtener_dataframe_de_bd(source_db_connection_string, sql_proveedores, db_user, db_psswd)\n",
    "categoriasProveedores = obtener_dataframe_de_bd(source_db_connection_string, sql_categoriasProveedores, db_user, db_psswd)\n",
    "personas = obtener_dataframe_de_bd(source_db_connection_string, sql_personas, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación\n",
    "Aspectos más relevantes\n",
    "- Se tiene como premisa que los días de pago no pueden ser negativos. \n",
    "- Existen proveedores que tienen más de una fila con nombre y un registro con el mismo nombre más la \"Inc\" o \"Ltd\". Se une con un solo proveedor porque se considera que es la misma persona jurídica.\n",
    "- Las tablas de categoriasProveedores y TiposTransaccion fueron analizadas ya se inspeccionaron.\n",
    "- Se ajustó el código postal para los proveedores.\n",
    "- Se identifican registros  duplicados que no son necesarios para el analisis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+--------------------+--------------------------+---------+-------------+\n",
      "|ID_Proveedor_T|              Nombre|CategoriaProveedorID|PersonaContactoPrincipalID|Dias_pago|Codigo_postal|\n",
      "+--------------+--------------------+--------------------+--------------------------+---------+-------------+\n",
      "|             4|      Fabrikam, Inc.|                   4|                        27|       30|        40351|\n",
      "|             5|Graphic Design In...|                   2|                        29|       14|        64847|\n",
      "|             7|       Litware, Inc.|                   5|                        33|       30|        95245|\n",
      "|             9|      Nod Publishers|                   2|                        37|        7|        27906|\n",
      "|            10|Northwind Electri...|                   3|                        39|       30|         7860|\n",
      "|            12|   The Phone Company|                   2|                        43|       30|        56732|\n",
      "|            13|      Woodgrove Bank|                   7|                        45|        7|        94101|\n",
      "|             2|       Contoso, Ltd.|                   2|                        23|       -7|        98253|\n",
      "|             6| Humongous Insurance|                   9|                        31|      -14|        37770|\n",
      "|             8|  Lucerne Publishing|                   2|                        35|      -30|        37659|\n",
      "+--------------+--------------------+--------------------+--------------------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el análisis es conveniente eliminar los registros duplicados que contienen los sufijos'Inc' o 'Ltd'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "|ID_Proveedor_T|             Nombre|CategoriaProveedorID|PersonaContactoPrincipalID|Dias_pago|Codigo_postal|\n",
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "|            12|  The Phone Company|                   2|                        43|       30|        56732|\n",
      "|            11|      Trey Research|                   8|                        41|       -7|        57543|\n",
      "|             6|Humongous Insurance|                   9|                        31|      -14|        37770|\n",
      "|             7|            Litware|                   5|                        33|       30|        95245|\n",
      "|             2|            Contoso|                   2|                        23|       -7|        98253|\n",
      "|            13|     Woodgrove Bank|                   7|                        45|        7|        94101|\n",
      "|             9|     Nod Publishers|                   2|                        37|        7|        27906|\n",
      "|             4|           Fabrikam|                   4|                        27|       30|        40351|\n",
      "|             1|A Datum Corporation|                   2|                        21|      -14|        46077|\n",
      "|             8| Lucerne Publishing|                   2|                        35|      -30|        37659|\n",
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se procede a retirar los sufijos ', Inc.' o ', Ltd.' de la columna 'Nombre'\n",
    "proveedores = proveedores.withColumn(\n",
    "    \"Nombre\",\n",
    "    when(proveedores[\"Nombre\"].endswith(\", Inc.\"), regexp_replace(proveedores[\"Nombre\"], \", Inc.$\", \"\"))\n",
    "    .when(proveedores[\"Nombre\"].endswith(\", Ltd.\"), regexp_replace(proveedores[\"Nombre\"], \", Ltd.$\", \"\"))\n",
    "    .otherwise(proveedores[\"Nombre\"])\n",
    ")\n",
    "\n",
    "# Se proceder a suprimir los registros duplicados por la columna nombre manteniendo la primera entrada de registro\n",
    "proveedores = proveedores.dropDuplicates(subset=['Nombre'])\n",
    "\n",
    "#Se muestra el resultado posterior a eliminar los duplicados\n",
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimación del valor absoluto de la variable Dias_pago por regla de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "|ID_Proveedor_T|             Nombre|CategoriaProveedorID|PersonaContactoPrincipalID|Dias_pago|Codigo_postal|\n",
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "|            12|  The Phone Company|                   2|                        43|       30|        56732|\n",
      "|            11|      Trey Research|                   8|                        41|        7|        57543|\n",
      "|             6|Humongous Insurance|                   9|                        31|       14|        37770|\n",
      "|             7|            Litware|                   5|                        33|       30|        95245|\n",
      "|             2|            Contoso|                   2|                        23|        7|        98253|\n",
      "|            13|     Woodgrove Bank|                   7|                        45|        7|        94101|\n",
      "|             9|     Nod Publishers|                   2|                        37|        7|        27906|\n",
      "|             4|           Fabrikam|                   4|                        27|       30|        40351|\n",
      "|             1|A Datum Corporation|                   2|                        21|       14|        46077|\n",
      "|             8| Lucerne Publishing|                   2|                        35|       30|        37659|\n",
      "+--------------+-------------------+--------------------+--------------------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proveedores = proveedores.withColumn(\"Dias_pago\", when(col(\"Dias_pago\") < 0, col(\"Dias_pago\") * -1).otherwise(col(\"Dias_pago\")))\n",
    "\n",
    "#Mostrar los valores luego de la actualización de los datos\n",
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se se procede a realizar una operación **join** con el DataFrame categoriasProveedores cocn el fin de cambiar la columna CategoriaProvedorId por Categoria.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+--------------------------+---------+-------------+--------------------+\n",
      "|ID_Proveedor_T|             Nombre|PersonaContactoPrincipalID|Dias_pago|Codigo_postal|           Categoria|\n",
      "+--------------+-------------------+--------------------------+---------+-------------+--------------------+\n",
      "|             7|            Litware|                        33|       30|        95245|            embalaje|\n",
      "|             6|Humongous Insurance|                        31|       14|        37770|servicios de seguros|\n",
      "|             4|           Fabrikam|                        27|       30|        40351|                ropa|\n",
      "|            11|      Trey Research|                        41|        7|        57543|servicios de mark...|\n",
      "|            13|     Woodgrove Bank|                        45|        7|        94101|servicios financi...|\n",
      "|            12|  The Phone Company|                        43|       30|        56732| productos novedosos|\n",
      "|             2|            Contoso|                        23|        7|        98253| productos novedosos|\n",
      "|             9|     Nod Publishers|                        37|        7|        27906| productos novedosos|\n",
      "|             1|A Datum Corporation|                        21|       14|        46077| productos novedosos|\n",
      "|             8| Lucerne Publishing|                        35|       30|        37659| productos novedosos|\n",
      "+--------------+-------------------+--------------------------+---------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se procede a unir los  DataFrames utilizando el campo 'CategoriaProveedorId'\n",
    "proveedores = proveedores.join(categoriasProveedores, on=\"CategoriaProveedorID\", how=\"left\")\n",
    "\n",
    "# Se proceder a renombrar la columna a 'Categoria'\n",
    "proveedores = proveedores.withColumnRenamed(\"CategoriaProveedor\", \"Categoria\")\n",
    "\n",
    "# Se proceder a elinniar la columna 'CategoriaProveedorID' \n",
    "proveedores = proveedores.drop(\"CategoriaProveedorID\")\n",
    "\n",
    "# Se muestran los datos luego de la actualización\n",
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proceder a reemplazar la variable **PersonaContactoPrincipalId** por **Contacto_principal** con una una la operación **join* con el DataFrame personas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+---------+-------------+--------------------+------------------+\n",
      "|ID_Proveedor_T|              Nombre|Dias_pago|Codigo_postal|           Categoria|Contacto_principal|\n",
      "+--------------+--------------------+---------+-------------+--------------------+------------------+\n",
      "|             1| A Datum Corporation|       14|        46077| productos novedosos|        Reio Kabin|\n",
      "|             2|             Contoso|        7|        98253| productos novedosos|   Hanna Mihhailov|\n",
      "|             4|            Fabrikam|       30|        40351|                ropa|       Bill Lawson|\n",
      "|             5|Graphic Design In...|       14|        64847| productos novedosos|        Penny Buck|\n",
      "|             6| Humongous Insurance|       14|        37770|servicios de seguros|Madelaine  Cartier|\n",
      "|             7|             Litware|       30|        95245|            embalaje|     Elias Myllari|\n",
      "|             8|  Lucerne Publishing|       30|        37659| productos novedosos|       Prem Prabhu|\n",
      "|             9|      Nod Publishers|        7|        27906| productos novedosos|      Marcos Costa|\n",
      "|            11|       Trey Research|        7|        57543|servicios de mark...|      Donald Jones|\n",
      "|            12|   The Phone Company|       30|        56732| productos novedosos|           Hai Dam|\n",
      "+--------------+--------------------+---------+-------------+--------------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Procedemos con la unión de los DataFrames utilizando el ID de la persona del contacto principal.\n",
    "proveedores = proveedores.join(personas, proveedores[\"PersonaContactoPrincipalId\"] == personas[\"ID_persona\"], \"left\")\n",
    "\n",
    "# Procemos a renombrar la columna a 'Contacto_principal'\n",
    "proveedores = proveedores.withColumnRenamed(\"NombreCompleto\", \"Contacto_principal\")\n",
    "\n",
    "# Se procede a eliminar columnas 'PersonaContactoPrincipalID' e 'ID_persona' \n",
    "proveedores = proveedores.drop(\"PersonaContactoPrincipalID\", \"ID_persona\")\n",
    "\n",
    "# Se muestra el cambio realizado sobre datos\n",
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a generar la llave de la bodega ID_Proveedor_DWH,ordenar las columnas y ordenar las filas por la llave para la bodega. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+--------------------+------------------+---------+-------------+\n",
      "|ID_Proveedor_DWH|ID_Proveedor_T|              Nombre|           Categoria|Contacto_principal|Dias_pago|Codigo_postal|\n",
      "+----------------+--------------+--------------------+--------------------+------------------+---------+-------------+\n",
      "|               1|             1| A Datum Corporation| productos novedosos|        Reio Kabin|       14|        46077|\n",
      "|               2|             2|             Contoso| productos novedosos|   Hanna Mihhailov|        7|        98253|\n",
      "|               3|             3|Consolidated Mess...|servicios de mens...|      Kerstin Parn|       30|        94101|\n",
      "|               4|             4|            Fabrikam|                ropa|       Bill Lawson|       30|        40351|\n",
      "|               5|             5|Graphic Design In...| productos novedosos|        Penny Buck|       14|        64847|\n",
      "|               6|             6| Humongous Insurance|servicios de seguros|Madelaine  Cartier|       14|        37770|\n",
      "|               7|             7|             Litware|            embalaje|     Elias Myllari|       30|        95245|\n",
      "|               8|             8|  Lucerne Publishing| productos novedosos|       Prem Prabhu|       30|        37659|\n",
      "|               9|             9|      Nod Publishers| productos novedosos|      Marcos Costa|        7|        27906|\n",
      "|              10|            10|Northwind Electri...|            juguetes|   Eliza Soderberg|       30|         7860|\n",
      "+----------------+--------------+--------------------+--------------------+------------------+---------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proveedores = proveedores.coalesce(1).withColumn('ID_Proveedor_DWH', f.monotonically_increasing_id() + 1)\n",
    "proveedores = proveedores.select('ID_Proveedor_DWH','ID_Proveedor_T','Nombre','Categoria','Contacto_principal','Dias_pago','Codigo_postal')\n",
    "proveedores.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, proveedores, 'Proveedor', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensión Fecha\n",
    "La fuente utilizada de datos es la tabla transaccional 'Movimientos'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_movimientos = '''(SELECT DISTINCT FechaTransaccion FROM WWImportersTransactional.movimientos) AS Temp_Movimientos'''\n",
    "\n",
    "fechas = obtener_dataframe_de_bd(source_db_connection_string, sql_movimientos, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aspectos más relevantes de la transformación\n",
    "- \"El formato de fechas manejado es YYYY-MM-DD HH:MM:SS contiene las unidades de timpo estándar como la hora, minutos y segundos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|FechaTransaccion|\n",
      "+----------------+\n",
      "|     Jan 20,2014|\n",
      "|     Jan 28,2014|\n",
      "|     Feb 01,2014|\n",
      "|     Mar 25,2014|\n",
      "|     May 01,2014|\n",
      "|     May 02,2014|\n",
      "|     May 10,2014|\n",
      "|     May 26,2014|\n",
      "|     Jun 02,2014|\n",
      "|     Jul 08,2014|\n",
      "+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fechas.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FechaTransaccion: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fechas.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proceder a crear una nueva columna de tipo Date con nombre 'Fecha' y convertir la cadena -string- de FechaTransaccion en datos tipo **date** a través de **to_date** de PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     Fecha|\n",
      "+----------+\n",
      "|2014-01-20|\n",
      "|2014-01-28|\n",
      "|2014-02-01|\n",
      "|2014-03-25|\n",
      "|2014-05-01|\n",
      "|2014-05-02|\n",
      "|2014-05-10|\n",
      "|2014-05-26|\n",
      "|2014-06-02|\n",
      "|2014-07-08|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se proceder a crear una nueva columna a partir del parsing de la FechaTransaccion\n",
    "fechas = fechas.withColumn(\"Fecha\", to_date(col(\"FechaTransaccion\"), \"MMM dd,yyyy\"))\n",
    "\n",
    "#Eliminamos la columna original\n",
    "fechas = fechas.drop(\"FechaTransaccion\")\n",
    "\n",
    "# Revisar el cambio en los datos\n",
    "fechas.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Fecha: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fechas.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la especificación del esquema, la fecha se almacena en el formato Dia, Mes, Año y Número de semana ISO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+----+-----------------+\n",
      "|     Fecha|Dia|Mes|Anio|Numero_semana_ISO|\n",
      "+----------+---+---+----+-----------------+\n",
      "|2014-01-20| 20|  1|2014|                4|\n",
      "|2014-01-28| 28|  1|2014|                5|\n",
      "|2014-02-01|  1|  2|2014|                5|\n",
      "|2014-03-25| 25|  3|2014|               13|\n",
      "|2014-05-01|  1|  5|2014|               18|\n",
      "|2014-05-02|  2|  5|2014|               18|\n",
      "|2014-05-10| 10|  5|2014|               19|\n",
      "|2014-05-26| 26|  5|2014|               22|\n",
      "|2014-06-02|  2|  6|2014|               23|\n",
      "|2014-07-08|  8|  7|2014|               28|\n",
      "+----------+---+---+----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculamos dia, mes y anio\n",
    "fechas = fechas.withColumn(\"Dia\", dayofmonth(col(\"Fecha\")))\n",
    "fechas = fechas.withColumn(\"Mes\", month(col(\"Fecha\")))\n",
    "fechas = fechas.withColumn(\"Anio\", year(col(\"Fecha\")))\n",
    "\n",
    "# Calculamos el numero de semana ISO\n",
    "fechas = fechas.withColumn(\"Numero_semana_ISO\", weekofyear(col(\"Fecha\")))\n",
    "\n",
    "# Comprobamos el cambio\n",
    "fechas.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a generar la columna ID_Fecha que corresponde a un numero del formato YYYYMMDD y ordenar las correspondientes columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---+---+----+-----------------+\n",
      "|ID_Fecha|     Fecha|Dia|Mes|Anio|Numero_semana_ISO|\n",
      "+--------+----------+---+---+----+-----------------+\n",
      "|20131231|2013-12-31| 31| 12|2013|                1|\n",
      "|20140101|2014-01-01|  1|  1|2014|                1|\n",
      "|20140102|2014-01-02|  2|  1|2014|                1|\n",
      "|20140103|2014-01-03|  3|  1|2014|                1|\n",
      "|20140104|2014-01-04|  4|  1|2014|                1|\n",
      "|20140106|2014-01-06|  6|  1|2014|                2|\n",
      "|20140107|2014-01-07|  7|  1|2014|                2|\n",
      "|20140108|2014-01-08|  8|  1|2014|                2|\n",
      "|20140109|2014-01-09|  9|  1|2014|                2|\n",
      "|20140110|2014-01-10| 10|  1|2014|                2|\n",
      "+--------+----------+---+---+----+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fechas = fechas.withColumn(\"ID_Fecha\", date_format(col(\"Fecha\"), \"yyyyMMdd\").cast(\"int\"))\n",
    "fechas = fechas.select('ID_Fecha','Fecha','Dia','Mes','Anio','Numero_semana_ISO')\n",
    "fechas = fechas.dropna()\n",
    "fechas = fechas.orderBy(col(\"ID_Fecha\"))\n",
    "fechas.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, fechas, 'Fecha', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensión TipoTransacción\n",
    "La fuente de datos es la tabla TiposTransaccion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_tipoTransaccion = '''(SELECT DISTINCT TipoTransaccionID AS ID_Tipo_transaccion_T, TipoTransaccionNombre AS Tipo FROM WWImportersTransactional.TiposTransaccion) AS Temp_TiposTransaccion'''\n",
    "\n",
    "tipoTransaccion = obtener_dataframe_de_bd(source_db_connection_string, sql_tipoTransaccion, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación\n",
    "Insights relavantes\n",
    "- El negocio indica que las tablas de categoriasProveedores y TiposTransaccion fueron analizadas previamente, por su grupo de consultores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------+\n",
      "|ID_Tipo_transaccion_T|                Tipo|\n",
      "+---------------------+--------------------+\n",
      "|                    2|Customer Credit Note|\n",
      "|                    3|Customer Payment ...|\n",
      "|                    4|     Customer Refund|\n",
      "|                    5|    Supplier Invoice|\n",
      "|                    6|Supplier Credit Note|\n",
      "|                    7|Supplier Payment ...|\n",
      "|                    8|     Supplier Refund|\n",
      "|                    9|      Stock Transfer|\n",
      "|                   10|         Stock Issue|\n",
      "|                   11|       Stock Receipt|\n",
      "+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipoTransaccion.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta tabla fue inspeccionada, y se prodece a adicionar la llave de la bodega 'ID_Tipo_transaccion_DWH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------------+--------------------+\n",
      "|ID_Tipo_transaccion_DWH|ID_Tipo_transaccion_T|                Tipo|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "|                      1|                    2|Customer Credit Note|\n",
      "|                      2|                    3|Customer Payment ...|\n",
      "|                      3|                    4|     Customer Refund|\n",
      "|                      4|                    5|    Supplier Invoice|\n",
      "|                      5|                    6|Supplier Credit Note|\n",
      "|                      6|                    7|Supplier Payment ...|\n",
      "|                      7|                    8|     Supplier Refund|\n",
      "|                      8|                    9|      Stock Transfer|\n",
      "|                      9|                   10|         Stock Issue|\n",
      "|                     10|                   11|       Stock Receipt|\n",
      "+-----------------------+---------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tipoTransaccion = tipoTransaccion.orderBy(col(\"ID_Tipo_transaccion_T\"))\n",
    "tipoTransaccion = tipoTransaccion.coalesce(1).withColumn('ID_Tipo_transaccion_DWH', f.monotonically_increasing_id() + 1)\n",
    "tipoTransaccion = tipoTransaccion.select('ID_Tipo_transaccion_DWH','ID_Tipo_transaccion_T','Tipo')\n",
    "tipoTransaccion.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, tipoTransaccion, 'TipoTransaccion', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hecho Movimiento\n",
    "Se procede a trabajar con la tabla movimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACCION\n",
    "sql_movimientos = '''(SELECT DISTINCT FechaTransaccion, ProductoID AS ID_Producto_T, ProveedorID AS ID_Proveedor_T, ClienteID AS ID_Cliente_T, TipoTransaccionID AS ID_Tipo_transaccion_T, Cantidad FROM WWImportersTransactional.movimientos) AS Temp_Movimientos'''\n",
    "\n",
    "movimientos = obtener_dataframe_de_bd(source_db_connection_string, sql_movimientos, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformación\n",
    "Aspectos más relevantes\n",
    "- Las cantidades negativas significan salidas de productos del inventario, es decir, una desminución del inventario de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "|FechaTransaccion|ID_Producto_T|ID_Proveedor_T|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|\n",
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "|     Jan 20,2014|          108|          NULL|       185.0|                   10|   -10.0|\n",
      "|     Jan 28,2014|          162|           4.0|         0.0|                   11|    10.0|\n",
      "|     Jan 28,2014|          216|          NULL|       474.0|                   10|   -10.0|\n",
      "|     Jan 28,2014|           22|           7.0|         0.0|                   11|    10.0|\n",
      "|     Jan 28,2014|           25|           7.0|         0.0|                   11|    10.0|\n",
      "|     Feb 01,2014|           14|          NULL|       444.0|                   10|   -10.0|\n",
      "|     Feb 01,2014|           75|           7.0|         0.0|                   11|    10.0|\n",
      "|     Mar 25,2014|           20|          NULL|       802.0|                   10|   -10.0|\n",
      "|     Mar 25,2014|           65|           4.0|         0.0|                   11|    10.0|\n",
      "|     Mar 25,2014|          130|          NULL|       487.0|                   10|   -10.0|\n",
      "+----------------+-------------+--------------+------------+---------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Mostrar los movimientos\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------------+---------------------+--------+--------+\n",
      "|ID_Producto_T|ID_Proveedor_T|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|ID_Fecha|\n",
      "+-------------+--------------+------------+---------------------+--------+--------+\n",
      "|          162|           4.0|         0.0|                   11|    10.0|20140128|\n",
      "|          216|          NULL|       474.0|                   10|   -10.0|20140128|\n",
      "|           22|           7.0|         0.0|                   11|    10.0|20140128|\n",
      "|           25|           7.0|         0.0|                   11|    10.0|20140128|\n",
      "|          108|          NULL|       185.0|                   10|   -10.0|20140120|\n",
      "|           20|          NULL|       802.0|                   10|   -10.0|20140325|\n",
      "|           65|           4.0|         0.0|                   11|    10.0|20140325|\n",
      "|          130|          NULL|       487.0|                   10|   -10.0|20140325|\n",
      "|          171|           7.0|         0.0|                   11|    10.0|20140325|\n",
      "|           14|          NULL|       444.0|                   10|   -10.0|20140201|\n",
      "+-------------+--------------+------------+---------------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se proceder a crear nueva columna a partir del parsing de la FechaTransaccion\n",
    "movimientos = movimientos.withColumn(\"Fecha\", to_date(col(\"FechaTransaccion\"), \"MMM dd,yyyy\"))\n",
    "\n",
    "# Se procede a eliminar la columna original\n",
    "movimientos = movimientos.drop(\"FechaTransaccion\")\n",
    "\n",
    "# Se procede a unir los DataFrames por 'Fecha'\n",
    "movimientos = movimientos.join(fechas, on=\"Fecha\", how=\"left\")\n",
    "\n",
    "# Se ejecuta una operación Drop a columnas no requerida\n",
    "movimientos = movimientos.drop(\"Fecha\", \"Dia\", \"Mes\", \"Anio\", \"Numero_semana_ISO\")\n",
    "\n",
    "# Se verifica la transformacion\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a convertir **ID_Producto_T** en **ID_Producto_DWH** esto con la operación **join** con la tabla **Producto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "|ID_Proveedor_T|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|ID_Fecha|ID_Producto_DWH|\n",
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "|           4.0|         0.0|                   11|    10.0|20140128|             60|\n",
      "|          NULL|       474.0|                   10|   -10.0|20140128|            102|\n",
      "|           7.0|         0.0|                   11|    10.0|20140128|            168|\n",
      "|           7.0|         0.0|                   11|    10.0|20140128|            119|\n",
      "|          NULL|       185.0|                   10|   -10.0|20140120|            202|\n",
      "|          NULL|       802.0|                   10|   -10.0|20140325|            167|\n",
      "|           4.0|         0.0|                   11|    10.0|20140325|            137|\n",
      "|          NULL|       487.0|                   10|   -10.0|20140325|            160|\n",
      "|           7.0|         0.0|                   11|    10.0|20140325|            218|\n",
      "|          NULL|       444.0|                   10|   -10.0|20140201|             26|\n",
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se procede a unir los DataFrames según el campo 'ID_Producto_T'\n",
    "movimientos = movimientos.join(productos, on=\"ID_Producto_T\", how=\"left\")\n",
    "\n",
    "# Se proceder a realizar ejecutar la operación Drop coloumnas no requeridad\n",
    "movimientos = movimientos.drop(\"ID_Producto_T\", \"NombreProducto\", \"Marca\", \"Color\", \"Necesita_refrigeracion\", \"Dias_tiempo_entrega\", \"PrecioRecomendado\", \"Impuesto\", \"PrecioUnitario\")\n",
    "\n",
    "#Se procede a verificar la transformacion\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a reemplazar el **ID_Proveedor_T** en **ID_Proveedor_DWH** considerando los datos vacios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de entradas vacias en 'ID_Proveedor_T': 50.19%\n"
     ]
    }
   ],
   "source": [
    "total_rows = movimientos.count()\n",
    "empty_entries = movimientos.filter(\n",
    "    col(\"ID_Proveedor_T\").isNull() | \n",
    "    col(\"ID_Proveedor_T\").eqNullSafe(\"\") | \n",
    "    isnan(col(\"ID_Proveedor_T\")) | \n",
    "    (trim(col(\"ID_Proveedor_T\")) == \"\")\n",
    ").count()\n",
    "percentage_empty = (empty_entries / total_rows) * 100\n",
    "\n",
    "print(f\"Porcentaje de entradas vacias en 'ID_Proveedor_T': {percentage_empty:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "|ID_Proveedor_T|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|ID_Fecha|ID_Producto_DWH|\n",
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "+--------------+------------+---------------------+--------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_empty_entries = movimientos.filter(col(\"ID_Proveedor_T\").isNotNull() & (col(\"ID_Proveedor_T\") != \"\"))\n",
    "non_empty_entries.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se proceder con la conversion de **ID_Proveedor_T** a **ID_Proveedor_DWH**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------------------+--------+--------+---------------+----------------+\n",
      "|ID_Cliente_T|ID_Tipo_transaccion_T|Cantidad|ID_Fecha|ID_Producto_DWH|ID_Proveedor_DWH|\n",
      "+------------+---------------------+--------+--------+---------------+----------------+\n",
      "|         0.0|                   11|    10.0|20140128|             60|            NULL|\n",
      "|       474.0|                   10|   -10.0|20140128|            102|            NULL|\n",
      "|         0.0|                   11|    10.0|20140128|            168|            NULL|\n",
      "|         0.0|                   11|    10.0|20140128|            119|            NULL|\n",
      "|       185.0|                   10|   -10.0|20140120|            202|            NULL|\n",
      "|       802.0|                   10|   -10.0|20140325|            167|            NULL|\n",
      "|         0.0|                   11|    10.0|20140325|            137|            NULL|\n",
      "|       487.0|                   10|   -10.0|20140325|            160|            NULL|\n",
      "|         0.0|                   11|    10.0|20140325|            218|            NULL|\n",
      "|       444.0|                   10|   -10.0|20140201|             26|            NULL|\n",
      "+------------+---------------------+--------+--------+---------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transformacipón de los campos vacios a None\n",
    "movimientos = movimientos.withColumn(\"ID_Proveedor_T\", when(col(\"ID_Proveedor_T\") != \"\", col(\"ID_Proveedor_T\")).otherwise(None))\n",
    "\n",
    "# Se procede a unir los DataFrames según 'ID_Proveedor_T'\n",
    "movimientos = movimientos.join(proveedores, on=\"ID_Proveedor_T\", how=\"left\")\n",
    "\n",
    "# Ejecutar la operación Drop de columnas no requeridas\n",
    "movimientos = movimientos.drop(\"Nombre\", \"Categoria\", \"Contacto_principal\", \"Dias_pago\", \"Codigo_postal\", \"ID_Proveedor_T\")\n",
    "\n",
    "#Verificar la transformacion\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizar la transformación de **ID_Cliente_T** a **ID_Cliente_DWH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------+--------+---------------+----------------+--------------+\n",
      "|ID_Tipo_transaccion_T|Cantidad|ID_Fecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|\n",
      "+---------------------+--------+--------+---------------+----------------+--------------+\n",
      "|                   11|    10.0|20140128|             60|            NULL|          NULL|\n",
      "|                   11|    10.0|20140128|            168|            NULL|          NULL|\n",
      "|                   11|    10.0|20140128|            119|            NULL|          NULL|\n",
      "|                   11|    10.0|20140325|            137|            NULL|          NULL|\n",
      "|                   11|    10.0|20140325|            218|            NULL|          NULL|\n",
      "|                   11|    10.0|20140201|            141|            NULL|          NULL|\n",
      "|                   10|   -10.0|20140325|            167|            NULL|             2|\n",
      "|                   10|   -10.0|20140201|             26|            NULL|           506|\n",
      "|                   10|   -10.0|20140120|            202|            NULL|           446|\n",
      "|                   10|   -10.0|20140128|            102|            NULL|           536|\n",
      "+---------------------+--------+--------+---------------+----------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se unen los DataFrames según en 'ID_Cliente_T'\n",
    "movimientos = movimientos.join(clientes, on=\"ID_Cliente_T\", how=\"left\")\n",
    "\n",
    "# Ejecutar operación Drop a las columnas no requeridas\n",
    "movimientos = movimientos.drop(\"ID_Cliente_T\", \"Nombre\", \"NombreCategoria\", \"NombreGrupoCompra\", \"ClienteFactura\", \"ID_CiudadEntrega\", \"LimiteCredito\", \"FechaAperturaCuenta\", \"DiasPago\")\n",
    "\n",
    "#Verificar la transformacion\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede reemplazar **ID_Tipo_transaccion_T** en **ID_Tipo_transaccion_DWH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------------+----------------+--------------+-----------------------+\n",
      "|Cantidad|ID_Fecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_transaccion_DWH|\n",
      "+--------+--------+---------------+----------------+--------------+-----------------------+\n",
      "|    10.0|20140128|             60|            NULL|          NULL|                     10|\n",
      "|    10.0|20140128|            168|            NULL|          NULL|                     10|\n",
      "|    10.0|20140128|            119|            NULL|          NULL|                     10|\n",
      "|    10.0|20140325|            137|            NULL|          NULL|                     10|\n",
      "|    10.0|20140325|            218|            NULL|          NULL|                     10|\n",
      "|    10.0|20140201|            141|            NULL|          NULL|                     10|\n",
      "|   -10.0|20140325|            167|            NULL|             2|                      9|\n",
      "|   -10.0|20140201|             26|            NULL|           506|                      9|\n",
      "|   -10.0|20140120|            202|            NULL|           446|                      9|\n",
      "|   -10.0|20140128|            102|            NULL|           536|                      9|\n",
      "+--------+--------+---------------+----------------+--------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se procede a unir los DataFrames según el 'ID_Tipo_transaccion_T'\n",
    "movimientos = movimientos.join(tipoTransaccion, on=\"ID_Tipo_transaccion_T\", how=\"left\")\n",
    "\n",
    "# Se ejecuta operación Drop a las columnas no requeridas\n",
    "movimientos = movimientos.drop(\"ID_Tipo_transaccion_T\", \"Tipo\")\n",
    "\n",
    "#Verificar la transformacion\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a reorganizar las columnas de la tabla movimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|ID_Fecha|ID_Producto_DWH|ID_Proveedor_DWH|ID_Cliente_DWH|ID_Tipo_transaccion_DWH|Cantidad|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "|20140128|             60|            NULL|          NULL|                     10|    10.0|\n",
      "|20140128|            168|            NULL|          NULL|                     10|    10.0|\n",
      "|20140128|            119|            NULL|          NULL|                     10|    10.0|\n",
      "|20140325|            137|            NULL|          NULL|                     10|    10.0|\n",
      "|20140325|            218|            NULL|          NULL|                     10|    10.0|\n",
      "|20140201|            141|            NULL|          NULL|                     10|    10.0|\n",
      "|20140120|            202|            NULL|           446|                      9|   -10.0|\n",
      "|20140201|             26|            NULL|           506|                      9|   -10.0|\n",
      "|20140128|            102|            NULL|           536|                      9|   -10.0|\n",
      "|20140325|            160|            NULL|           549|                      9|   -10.0|\n",
      "+--------+---------------+----------------+--------------+-----------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movimientos = movimientos.select('ID_Fecha','ID_Producto_DWH','ID_Proveedor_DWH','ID_Cliente_DWH','ID_Tipo_transaccion_DWH', 'Cantidad')\n",
    "movimientos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guardar_db(dest_db_connection_string, movimientos, 'Hecho_Movimiento', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta actividad se finaliza el proceso ETL (Extracción, Transformación y Carga) para las dimensiones Proveedor, Fecha y TipoTransaccion, y de la tabla \"Hecho_Movimiento\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euvEeguv86v9"
   },
   "source": [
    "## 4. Cierre\n",
    "Completado este tutorial, ya sabe cómo realizar ETL básicos en PySpark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaFNpgeW86v9"
   },
   "source": [
    "## 5. Información adicional\n",
    "\n",
    "Si quiere conocer más sobre PySpark la guía más detallada es la documentación oficial, la cual puede encontrar acá: https://spark.apache.org/docs/latest/api/python/index.html <br>\n",
    "Para ir directamente a la documentación de PySpark SQL, donde está la información sobre los DataFrames, haga clic en este enlace: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html <br>\n",
    "\n",
    "El Capítulo 2 del libro <i>Learn PySpark : Build Python-based Machine Learning and Deep Learning Models, New York: Apress. 2019</i> de Pramod Singh contiene muchos ejemplos útiles, puede encontrarlo en la biblioteca virtual de la universidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kIcwffv86v-"
   },
   "source": [
    "## 6. Preguntas frecuentes\n",
    "\n",
    "- Si al intentar escribir un <i>dataframe</i> obtiene un error en el formato: \n",
    "    ```\n",
    "    path file:<PATH>/dw/<PATH> already exists.;\n",
    "    ```\n",
    "    Borre la carpeta indicada en el error y vuelva a intentar.\n",
    "\n",
    "- Si al ejecutar su código obtiene el error: \n",
    "    ```\n",
    "    ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=tutorial ETL PySpark, master=local) created by __init__ at <ipython-input-4-64455da959dd>:92 \n",
    "\n",
    "    ```\n",
    "    reinicie el kernel del notebook y vuelva a intentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6J9jYwEJ86v-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vtE61qk986vx",
    "X9Oou0g986vy",
    "B5kFkHTD86vz",
    "ddFhEOmL86vz",
    "MuvVgJ4R86v0",
    "BZjDeVYd86v1",
    "_7xbgfCk86v1",
    "Rh_102Yy86v1",
    "HogvCqW_86v2",
    "9rKmT9jd86v2",
    "R9SnkMUH86v3",
    "k8O1GvOd86v3",
    "Mo633Vpg86v3",
    "i36NawhX86v4",
    "LvgnsPfK86v4",
    "dTv_CIOT86v5",
    "N9f10qpB86v9"
   ],
   "name": "MISW-ETL-TutorialETL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
