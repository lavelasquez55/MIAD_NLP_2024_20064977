{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcY9y56n86vn"
      },
      "source": [
        "# Tutorial: creación de ETLs con PySpark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.26.tar.gz\n",
        "!tar -xzf mysql-connector-java-8.0.26.tar.gz\n",
        "!mv mysql-connector-java-8.0.26/mysql-connector-java-8.0.26.jar ./"
      ],
      "metadata": {
        "id": "vJBk8-i5sOBl",
        "outputId": "dabc6760-3ef3-4abc-838d-53fbba8475ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "--2024-07-18 01:41:07--  https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.26.tar.gz\n",
            "Resolving dev.mysql.com (dev.mysql.com)... 23.61.106.232, 2600:1407:7400:58a::2e31, 2600:1407:7400:586::2e31\n",
            "Connecting to dev.mysql.com (dev.mysql.com)|23.61.106.232|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://cdn.mysql.com//archives/mysql-connector-java-8.0/mysql-connector-java-8.0.26.tar.gz [following]\n",
            "--2024-07-18 01:41:07--  https://cdn.mysql.com//archives/mysql-connector-java-8.0/mysql-connector-java-8.0.26.tar.gz\n",
            "Resolving cdn.mysql.com (cdn.mysql.com)... 23.61.42.21, 2600:1407:7400:19c::1d68, 2600:1407:7400:19f::1d68\n",
            "Connecting to cdn.mysql.com (cdn.mysql.com)|23.61.42.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4180706 (4.0M) [application/x-tar-gz]\n",
            "Saving to: ‘mysql-connector-java-8.0.26.tar.gz.1’\n",
            "\n",
            "mysql-connector-jav 100%[===================>]   3.99M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-07-18 01:41:08 (40.2 MB/s) - ‘mysql-connector-java-8.0.26.tar.gz.1’ saved [4180706/4180706]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcg5UCbU86vp"
      },
      "source": [
        "## 1. Introducción\n",
        "    ¿Qué aprenderá?\n",
        "\tEn este tutorial aprenderá cómo puede utilizar PySpark para crear un proceso de ETL básico.\n",
        "\n",
        "\t¿Qué construirá?     \n",
        "        Construirá un ETL que toma los datos desde la base de datos transacional de WideWorldImporters (WWImportersTransactional), los transforma  a una representación cercana al análisis y los  almacena en la base de datos relacional WWImportersDWH.\n",
        "    \n",
        "\t¿Para qué?\n",
        "\tLa construcción de ETLs que se ajusten a modelos multidimensionales es un paso necesario dentro de un proceso de analìtica 1.0 , pues permite tomar los datos crudos de una fuente, generalmente transaccional, para transformarlos en datos limpios que puedan utilizarse para la toma de decisiones.\n",
        "    \n",
        "    ¿Qué necesita?\n",
        "    1. Python 3 con pip instalado\n",
        "    2. Jupyter notebook\n",
        "    3. Paquetes: Pyspark (3.0.1) y pandas (1.2.1)\n",
        "    4. Controlador Connector J de MySQL (ya se encuentra instalado)\n",
        "    5. Servidor SQL con base de datos relacional \"WWImportersTransactional\" y base de datos relacional que corresponde a la bodega de WWI \"Estudiante_i\"\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqQVz5s686vq"
      },
      "source": [
        "## 2. Proceso de ETL para una dimensión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2UT2Ia586vr"
      },
      "source": [
        "En este proceso de ETL, se extraen los datos de las **órdenes de compra** de una base de datos transaccional y se almacenan en otra base de datos que corresponde a la bodega de datos, siguiendo una aproximación ROLAP. A continuación, se presenta el modelo multidimensional que es el modelo conceptual que representa el proceso de registro de órdenes de compra. Este modelo se utilizó para crear las tablas en la bodega de datos que representan el proceso de negocio y que serán cargadas como resultado del proceso ETL.\n",
        "\n",
        "Tenga en cuenta que las llaves ID_XXXX presentes en el modelo hacen referencia a las llaves de la bodega. Por otra parte, en el proceso de ETL se van a tener en cuenta las llaves transaccionales (**WWImportersTransactional**). La nomenclatura para utilizar es:\n",
        "\n",
        "1.   ID_XXXX_DWH, para las llaves de la bodega.\n",
        "2.   ID_XXXX_T, para las llaves transaccionales.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpOSEfhX86vs"
      },
      "source": [
        "![Modelo ordenes](https://github.com/lavelasquez55/MIAD_NLP_2024_20064977/blob/main/WWI_modelo_ordenes.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rg1M_rdU86vs"
      },
      "source": [
        "El proceso de ETL debe ser diseñado antes de implementarse. A partir de las conclusiones del entendimiento de datos sabemos las fuentes que se van a  utilizar y la relación entre las fuentes. Adicionalmente, se cuenta con las respuestas de la organización a las preguntas, resultado del entendimiento de datos. De esa manera sabemos cómo se deben manipular los datos.\n",
        "\n",
        "Este proceso de ETL lo dividimos en seis bloques, uno para cada dimensión o <i>tabla de hechos</i> del modelo, con la única excepción de la dimensión de fecha que, por ser una dimensión especial que se genera de forma independiente, no se incluye aquí:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIa8WW1M86vt"
      },
      "source": [
        "![ETL](https://github.com/lavelasquez55/MIAD_NLP_2024_20064977/blob/main/Disenio_ETL.PNG?raw=1)\n",
        "\n",
        "Recuerde que este es el diseño general. En el diseño completo se deben incluir las transformaciones realizadas a los datos a utilizarse en las dimensiones y tablas de hecho del modelo multidimensional, de acuerdo con lo que se muestra en la infografía de arquitectura de componentes (Componente proceso ETL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "os1iJYmu86vt"
      },
      "outputs": [],
      "source": [
        "# Configuración servidor base de datos transaccional\n",
        "# Recuerde usar Estudiante_i como usuario y la contraseña asigana en el excel de conexión a maquina virtual como contraseña\n",
        "db_user = 'Estudiante_24_202413'\n",
        "db_psswd = 'aabb1122'\n",
        "source_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/RaSaTransaccional_ETL'\n",
        "\n",
        "dest_db_connection_string = 'jdbc:mysql://157.253.236.120:8080/Estudiante_24_202413'\n",
        "\n",
        "# Driver de conexion\n",
        "path_jar_driver = '/content/mysql-connector-java-8.0.26.jar'\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HAGk_V1986vu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pyspark.sql import functions as f, SparkSession, types as t\n",
        "from pyspark import SparkContext, SparkConf, SQLContext\n",
        "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TQ3DM_Xf86vv",
        "outputId": "4e87facf-ea1b-4870-bd8a-ce57e8532436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SparkConf' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8afff9838bd2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Configuración de la sesión\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spark.driver.extraClassPath'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_jar_driver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspark_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SparkConf' is not defined"
          ]
        }
      ],
      "source": [
        "#Configuración de la sesión\n",
        "conf=SparkConf() \\\n",
        "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
        "\n",
        "spark_context = SparkContext(conf=conf)\n",
        "sql_context = SQLContext(spark_context)\n",
        "spark = sql_context.sparkSession"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buA7s-vL86vw"
      },
      "source": [
        "### Conexión y carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_QZ-j9q86vw"
      },
      "source": [
        "Se define la función para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhy0jbh_86vw"
      },
      "outputs": [],
      "source": [
        "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
        "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
        "\n",
        "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
        "    df_bd = spark.read.format('jdbc')\\\n",
        "        .option('url', db_connection_string) \\\n",
        "        .option('dbtable', sql) \\\n",
        "        .option('user', db_user) \\\n",
        "        .option('password', db_psswd) \\\n",
        "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
        "        .load()\n",
        "    return df_bd\n",
        "\n",
        "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
        "    df.select('*').write.format('jdbc') \\\n",
        "      .mode('append') \\\n",
        "      .option('url', db_connection_string) \\\n",
        "      .option('dbtable', tabla) \\\n",
        "      .option('user', db_user) \\\n",
        "      .option('password', db_psswd) \\\n",
        "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
        "      .save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhFsv4ba86vw"
      },
      "source": [
        "### BLOQUE 1\n",
        "Empezamos con el bloque 1: la dimensión <i>Empleado</i>, su fuente de datos viene de la tabla transaccional <i>Personas</i>. En la sentencia SQL filtramos usando WHERE para seleccionar solo las personas que sean vendedores y recuperamos únicamente los atributos que queremos, de acuerdo con  modelo dimensional. Recuerde que también puede usar el **.select()** de pyspark si no conoce los atributos de las tablas transaccionales. Sin embargo, es más eficiente aplicar el filtro en la consulta, ya que no trae a memoria más información de la necesaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNKxFA-f86vx"
      },
      "source": [
        "#### Extracción\n",
        "A continuación, nos conectamos a la base de datos y extraemos la información deseada por medio de SQL, cargandola en un DataFrame PySpark, es decir en memoria. Note que aquí se pueden renombrar los atributos con la estructura <i>nombreActual AS nuevoNombre</i>. De la tabla de personas, En este paso, solo nos interesan los empleados, por lo cual se hace un filtro por medio del WHERE, buscando las personas cuyo atributo EsVendedor sea igual a 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_areasServicio = '''(SELECT DISTINCT IdAreaDeServicio_T, NombreAreaDeServicio, IdGeografia_T, Condado, Estado, PoblacionAct, Area, Densidad, Fecha FROM RaSaTransaccional_ETL.FuenteAreasDeServicio_ETL) AS Temp_AreaServicio'''\n",
        "areasServicio = obtener_dataframe_de_bd(source_db_connection_string, sql_areasServicio, db_user, db_psswd)\n",
        "areasServicio.show(10)"
      ],
      "metadata": {
        "id": "cCF3-FUQA0vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_areasServicio = '''(SELECT DISTINCT IdAreaDeServicio_T, NombreAreaDeServicio, IdGeografia_T, Condado, Estado, PoblacionAct, Area, Densidad, Fecha FROM RaSaTransaccional_ETL.FuenteCondicionesDePago_ETL) AS Temp_CondicionesPago'''\n",
        "areasServicio = obtener_dataframe_de_bd(source_db_connection_string, sql_areasServicio, db_user, db_psswd)\n",
        "areasServicio.show(10)"
      ],
      "metadata": {
        "id": "GOouaFmECKjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IopBNYuc86vx"
      },
      "outputs": [],
      "source": [
        "sql_condicionesPago = '''(SELECT DISTINCT IdCondicionesDePago_T, Descripcion, Tipo FROM RaSaTransaccional_ETL.FuenteCondicionesDePago_ETL) AS Temp_CondicionesPago'''\n",
        "condicionesPago = obtener_dataframe_de_bd(source_db_connection_string, sql_condicionesPago, db_user, db_psswd)\n",
        "condicionesPago.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sql_tiposBeneficio = '''(SELECT DISTINCT IdTipoBeneficio_T, Nombre, UnidadDelLimite, EsEHB, EstaCubiertaPorSeguro, TieneLimiteCuantitativo, ExcluidoDelDesembolsoMaximoDentroDeLaRed, ExcluidoDelDesembolsoMaximoFueraDeLaRed, Fecha  FROM RaSaTransaccional_ETL.FuenteTiposBeneficio_ETL) AS Temp_TiposBeneficio'''\n",
        "tiposBeneficio = obtener_dataframe_de_bd(source_db_connection_string, sql_tiposBeneficio, db_user, db_psswd)\n",
        "tiposBeneficio.show(10)"
      ],
      "metadata": {
        "id": "SkVKyJHlDZV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sql_nivelesServicio = '''(SELECT DISTINCT IdNivelDeServicio_DWH, IdNivelDeServicio_T, Descripcion FROM RaSaTransaccional_ETL.NivelesDeServicio) AS Temp_NivelesServicio'''\n",
        "nivelesServicio = obtener_dataframe_de_bd(source_db_connection_string, sql_nivelesServicio, db_user, db_psswd)\n",
        "nivelesServicio.show(10)"
      ],
      "metadata": {
        "id": "MSBgLUA0EKuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtE61qk986vx"
      },
      "source": [
        "#### Transformación\n",
        "Recuerde que, puede hacer uso de selectExpr, filter, where entre otras de PySpark para modificar los datos cargados. Por ejemplo, el siguiente código utiliza <i>selectExpr</i> para renombrar la columna ID_Empleado por ID_Empleado_T, esta es la convención que vamos a utilizar: \"_T\" para indicar que el ID es el que estaba en la base de datos transaccional y \"_DWH\" para indicar que son ID's propios de la bodega. Usamos withColumn y monotonicallu_increasing_id para crear un ID acumulativo para cada registro en el dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e-zDXcspz8J"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "empleados = empleados.selectExpr('ID_Empleado as ID_Empleado_T','Nombre')\n",
        "empleados = empleados.coalesce(1).withColumn('ID_Empleado_DWH', f.monotonically_increasing_id() + 1)\n",
        "empleados = empleados.select('ID_Empleado_DWH','ID_Empleado_T','Nombre')\n",
        "empleados.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Oou0g986vy"
      },
      "source": [
        "#### Carga\n",
        "Una vez realizado esto, se guardan los resultados en la base de datos destino\n",
        "\n",
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qICUWYCa86vy"
      },
      "outputs": [],
      "source": [
        "# CARGUE\n",
        "guardar_db(dest_db_connection_string, empleados,'Estudiante_i_XXXXXX.Empleados', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6k37LtO86vy"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvj5E1GS86vz"
      },
      "source": [
        "### BLOQUE 2\n",
        "Empezamos el bloque 2: dimensión ciudad. Su fuente de datos es una combinación de las tablas transaccionales <i>paises, provinciasEstados y ciudades</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5kFkHTD86vz"
      },
      "source": [
        "#### Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEW2mcMn86vz"
      },
      "outputs": [],
      "source": [
        "#EXTRACCION\n",
        "sql_paises = '''(SELECT DISTINCT ID_Pais, Nombre, Continente, Region, Subregion FROM WWImportersTransactional.Paises) AS Temp_paises'''\n",
        "sql_provincias_estados = '''(SELECT DISTINCT ID_EstadosProvincias AS ID_EstadoProvincia, NombreEstadoProvincia, TerritorioVentas, ID_Pais FROM WWImportersTransactional.EstadosProvincias) AS Temp_estados_provincias'''\n",
        "sql_ciudades = '''(SELECT DISTINCT ID_ciudad as ID_ciudad_T, NombreCiudad, ID_EstadoProvincia, Poblacion FROM WWImportersTransactional.Ciudades) AS Temp_ciudades'''\n",
        "\n",
        "paises = obtener_dataframe_de_bd(source_db_connection_string, sql_paises, db_user, db_psswd)\n",
        "provincias_estados = obtener_dataframe_de_bd(source_db_connection_string, sql_provincias_estados, db_user, db_psswd)\n",
        "ciudades = obtener_dataframe_de_bd(source_db_connection_string, sql_ciudades, db_user, db_psswd)\n",
        "\n",
        "print(ciudades.columns, paises.columns, provincias_estados.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddFhEOmL86vz"
      },
      "source": [
        "#### Transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8un2p4so86v0"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "ciudades = ciudades.join(provincias_estados, how = 'left', on = 'ID_EstadoProvincia')\n",
        "ciudades = ciudades.join(paises, how = 'left', on = 'ID_Pais')\n",
        "ciudades = ciudades.coalesce(1).withColumn('ID_Ciudad_DWH', f.monotonically_increasing_id() + 1)\n",
        "ciudades = ciudades.select('ID_Ciudad_DWH','ID_ciudad_T','NombreCiudad','Continente','Nombre','Poblacion',\n",
        "                          'Region','TerritorioVentas','NombreEstadoProvincia','Subregion') \\\n",
        "                    .withColumnRenamed('Nombre','Pais')\n",
        "ciudades.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuvVgJ4R86v0"
      },
      "source": [
        "#### Carga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGrTaflppz8L"
      },
      "source": [
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCC2zZqY86v0"
      },
      "outputs": [],
      "source": [
        "# CARGUE\n",
        "guardar_db(dest_db_connection_string, ciudades,'Estudiante_i_XXXXXX.Ciudad', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fo-J97586v0"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HpgwA6t86v0"
      },
      "source": [
        "### BLOQUE 3\n",
        "Bloque 3: dimensión paquete. Su fuente de datos es la tabla transaccional <i>Paquetes</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZjDeVYd86v1"
      },
      "source": [
        "#### Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HTzU96W86v1"
      },
      "outputs": [],
      "source": [
        "#EXTRACCION\n",
        "sql_paquetes = '''(SELECT DISTINCT ID_TipoPaquete AS ID_TipoPaquete_T, TipoPaquete AS Nombre FROM WWImportersTransactional.Paquetes) AS Temp_Paquetes'''\n",
        "paquetes = obtener_dataframe_de_bd(source_db_connection_string, sql_paquetes, db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7xbgfCk86v1"
      },
      "source": [
        "#### Transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97vmyl3Q86v1"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "paquetes = paquetes.coalesce(1).withColumn('ID_TipoPaquete_DWH', f.monotonically_increasing_id() + 1)\n",
        "paquetes = paquetes.select('ID_TipoPaquete_DWH','ID_TipoPaquete_T','Nombre')\n",
        "paquetes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh_102Yy86v1"
      },
      "source": [
        "#### Carga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01yupNNHpz8M"
      },
      "source": [
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpbxgpWn86v1"
      },
      "outputs": [],
      "source": [
        "# CARGUE\n",
        "guardar_db(dest_db_connection_string, paquetes,'Estudiante_i_XXXXXX.TipoPaquete', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTy1oE3V86v2"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYetZ2Ip86v2"
      },
      "source": [
        "### BLOQUE 4\n",
        "Bloque 4: dimensión producto, su fuente de datos es la combinación entre las tablas transaccionales Productos y Colores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HogvCqW_86v2"
      },
      "source": [
        "#### Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEJjQslF86v2"
      },
      "outputs": [],
      "source": [
        "sql_productos = '''(SELECT DISTINCT ID_Producto as ID_Producto_T, ID_Color, NombreProducto, Marca, Necesita_refrigeracion, Dias_tiempo_entrega, Impuesto, PrecioUnitario, PrecioRecomendado FROM WWImportersTransactional.Producto) AS Temp_productos'''\n",
        "sql_colores = '''(SELECT DISTINCT ID_Color, Color FROM WWImportersTransactional.Colores) AS Temp_colores'''\n",
        "\n",
        "productos = obtener_dataframe_de_bd(source_db_connection_string, sql_productos, db_user, db_psswd)\n",
        "colores = obtener_dataframe_de_bd(source_db_connection_string, sql_colores, db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rKmT9jd86v2"
      },
      "source": [
        "#### Transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "petU8G6K86v2"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "productos = productos.join(colores, how = 'left', on = 'ID_Color').fillna({'Color': 'Missing'})\n",
        "productos = productos.coalesce(1).withColumn('ID_Producto_DWH', f.monotonically_increasing_id() + 1)\n",
        "productos = productos.select('ID_Producto_DWH','ID_Producto_T','NombreProducto','Marca','Color','Necesita_refrigeracion','Dias_tiempo_entrega','PrecioRecomendado','Impuesto','PrecioUnitario')\n",
        "productos.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9SnkMUH86v3"
      },
      "source": [
        "#### Carga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pyul350pz8O"
      },
      "source": [
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMArotXz86v3"
      },
      "outputs": [],
      "source": [
        "# CARGUE\n",
        "guardar_db(dest_db_connection_string, productos,'Estudiante_i_XXXXXX.Producto', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YglraEoA86v3"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM4L4jA086v3"
      },
      "source": [
        "### BLOQUE 5\n",
        "Bloque 5: dimensión cliente. Su fuente de datos es la combinación entre las tablas transaccionales Categorias de cliente, Grupos de compra y Clientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8O1GvOd86v3"
      },
      "source": [
        "#### Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znROuHS086v3"
      },
      "outputs": [],
      "source": [
        "sql_categoriasCliente = '''(SELECT DISTINCT ID_Categoria, NombreCategoria FROM WWImportersTransactional.CategoriasCliente) AS Temp_categoriasclientes'''\n",
        "sql_gruposCompra = '''(SELECT DISTINCT ID_GrupoCompra, NombreGrupoCompra FROM WWImportersTransactional.GruposCompra) AS Temp_gruposcompra'''\n",
        "sql_clientes = '''(SELECT DISTINCT ID_Cliente as ID_Cliente_T, Nombre, ClienteFactura, ID_Categoria, ID_GrupoCompra, ID_CiudadEntrega, LimiteCredito, FechaAperturaCuenta, DiasPago FROM WWImportersTransactional.Clientes) AS Temp_clientes'''\n",
        "\n",
        "categoriasCliente = obtener_dataframe_de_bd(source_db_connection_string, sql_categoriasCliente, db_user, db_psswd)\n",
        "gruposCompra = obtener_dataframe_de_bd(source_db_connection_string, sql_gruposCompra, db_user, db_psswd)\n",
        "clientes = obtener_dataframe_de_bd(source_db_connection_string, sql_clientes, db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo633Vpg86v3"
      },
      "source": [
        "#### Transformación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwK8bV8Z86v3"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "# EL SUPUESTO QUE SE TIENE ES QUE TODOS LOS CLIENTES TIENEN TODOS SUS DATOS DE CATEGORIA Y GRUPO Y NO SE ESTÁN PERDIENDO CLIENTES AL REALIZAR ESTE JOIN\n",
        "clientes = clientes.join(gruposCompra, how = 'left', on = 'ID_GrupoCompra')\n",
        "clientes = clientes.alias('cl').join(categoriasCliente.alias('ct'), how = 'left', on = 'ID_Categoria') \\\n",
        ".select([col('cl.ID_Cliente_T'),col('cl.Nombre'),col('ct.NombreCategoria'),col('cl.NombreGrupoCompra') \\\n",
        "        ,col('cl.ClienteFactura'),col('cl.ID_CiudadEntrega'),col('cl.LimiteCredito'),col('cl.FechaAperturaCuenta'),col('cl.DiasPago')])\n",
        "clientes = clientes.coalesce(1).withColumn('ID_Cliente_DWH', f.monotonically_increasing_id() + 1)\n",
        "clientes = clientes.select('ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
        "                          'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago')\n",
        "\n",
        "clientes = clientes.fillna({'NombreCategoria':'Missing','NombreGrupoCompra':'Missing'})\n",
        "clientes.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQQjVAydpz8P"
      },
      "outputs": [],
      "source": [
        "# Crea el registro para el id = 0\n",
        "clientes_0 = [('0','','Missing','Missing','Missing','0','0','','','')]\n",
        "columns = ['ID_Cliente_DWH','ID_Cliente_T','Nombre','NombreCategoria','NombreGrupoCompra','ClienteFactura',\n",
        "            'ID_CiudadEntrega','LimiteCredito','FechaAperturaCuenta','DiasPago']\n",
        "cliente_0 = spark.createDataFrame(data=clientes_0,schema=columns)\n",
        "cliente_0.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KM_jdtHPpz8P"
      },
      "outputs": [],
      "source": [
        "clientes = clientes.union(cliente_0)\n",
        "clientes.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PwnNP2-pz8Q"
      },
      "outputs": [],
      "source": [
        "# Se ordena por el identificador DWH\n",
        "clientes = clientes.withColumn('ID_Cliente_DWH',col('ID_Cliente_DWH').cast('int')).orderBy(col('ID_Cliente_DWH'))\n",
        "clientes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i36NawhX86v4"
      },
      "source": [
        "#### Carga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOSRp5K1pz8Q"
      },
      "source": [
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcvMzmCf86v4"
      },
      "outputs": [],
      "source": [
        "# CARGUE\n",
        "guardar_db(dest_db_connection_string,clientes,'Estudiante_i_XXXXXX.Cliente', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMyvdEB-86v4"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ocmdLWv86v4"
      },
      "source": [
        "### BLOQUE 6\n",
        "Bloque 6: Hecho orden. Su fuente de datos es la combinación entre las tablas transaccionales Ordenes y detalles de orden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvgnsPfK86v4"
      },
      "source": [
        "#### Extracción"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b4Qs9_886v4"
      },
      "outputs": [],
      "source": [
        "sql_ordenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.Ordenes) AS Temp_ordenes'''\n",
        "sql_detallesOrdenes = '''(SELECT DISTINCT * FROM WWImportersTransactional.DetallesOrdenes) AS Temp_detallesordenes'''\n",
        "ordenes = obtener_dataframe_de_bd(source_db_connection_string, sql_ordenes, db_user, db_psswd)\n",
        "detallesOrdenes = obtener_dataframe_de_bd(source_db_connection_string, sql_detallesOrdenes, db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTv_CIOT86v5"
      },
      "source": [
        "#### Transformación\n",
        "Estas son las respuestas de Wide World Importers a los conclusiones obtenidas en el entendimiento de los datos:\n",
        "- La regla de negocio \"La tasa de impuesto es de 10% o 15%\" es correcta, pero habian errores en la tabla original, que fueron corregidos.\n",
        "- Para la segunda regla de negocio: \"Son 73.595 órdenes detalladas en 231.412 lineas de detalle de órdenes realizadas desde 2013\", si faltaban datos, los cuales fueron completados, y nos dicen que en cuanto a consistencia ellos revisaron las tablas e hicieron correcciones, pero que los duplicados completos de ordenes los eliminemos\n",
        "- \"El formato de fechas manejado es YYYY-MM-DD HH:MM:SS si tienen hora, minutos y segundos. De lo contrario el formato es YYYY-MM-DD\": En cuanto a formatos de fechas estan de acuerdo con que los estandarizemos y el formato sea el especificado en la regla\n",
        "- Para las descripciones de productos que eran \"a\", se actualizaron a los valores reales.\n",
        "- Se pueden eliminar las columnas Comenarios, Instrucciones_de_entrega y comentarios_internos porque estan vacias.\n",
        "- A pesar de estar en un proceso de mejorar la calidad de los datos y mantener los nulos nos ayudaría a reflejar esa calidad, de la mano con el grupo de analitica de WWI se decide imputar por la media el valor extremo de la variable Cantidad\n",
        "- Para las ordenes las columnas Seleccionado_por_ID_de_persona, ID_de_pedido_pendiente, Seleccion_completada_cuando, y para las columnas Seleccion_completada_cuando de la tabla detalles de ordenes, se decide mantener los valores vacíos, sin embargo para la variable Precio_unitario el negocio reviso y complemento los valores faltantes\n",
        "\n",
        "Las tablas usadas en el tutorial de entendimiento de datos estaran disponibles para su revision con los siguientes nombres: OrdenesCopia y DetallesOrdenesCopia.\n",
        "\n",
        "Para este tutorial vamos a trabajar con unas tablas que dadas las conclusiones del tutorial de entendimiento, WWImporters revisó los datos originales, creo tablas y las llamo \"Ordenes\" y \"DetallesOrdenes\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcHdgPzj86v5"
      },
      "source": [
        "Se hace una verificación de los valores de la tasa de impuesto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GT5i7Yjq86v5"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes.select(\"Tasa_de_impuesto\").distinct().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI27nmvB86v5"
      },
      "source": [
        "Se hace una verificación del rango de fechas disponible en los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0GmNF6x86v5"
      },
      "outputs": [],
      "source": [
        "ordenes.agg({\"Fecha_de_pedido\": \"min\"}).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAp83aSn86v6"
      },
      "source": [
        "Se elimina columnas Comenarios, Instrucciones_de_entrega y comentarios_internos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX2Wl4zo86v6"
      },
      "outputs": [],
      "source": [
        "ordenes = ordenes.drop(*[\"Comentarios\", \"Instrucciones_de_entrega\",\"comentarios_internos\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfONrMtq86v6"
      },
      "source": [
        "Se eliminan duplicados totales de ordenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3KbTJ4k86v6"
      },
      "outputs": [],
      "source": [
        "print((ordenes.count(),ordenes.distinct().count()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocWjOSPD86v6"
      },
      "outputs": [],
      "source": [
        "ordenes = ordenes.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qF5L6I186v6"
      },
      "outputs": [],
      "source": [
        "print((ordenes.count(),ordenes.distinct().count()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqSCkt_V86v6"
      },
      "source": [
        "Se hace verificación de consistencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXNKhNV986v7"
      },
      "outputs": [],
      "source": [
        "#consistencia: revisar genially: definicion de consistencia\n",
        "ids_ordenes = set([x.ID_de_pedido for x in ordenes.select('ID_de_pedido').collect()])\n",
        "ids_detalles = set([x.ID_de_pedido for x in detallesOrdenes.select('ID_de_pedido').collect()])\n",
        "\n",
        "len(ids_ordenes-ids_detalles), len(ids_detalles-ids_ordenes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB8BrURo86v7"
      },
      "source": [
        "En el siguiente código para el manejo de fechas, pasamos del formato MM dd,YYYY al formato establecido en la regla de negocio<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajB_7vTr86v7"
      },
      "outputs": [],
      "source": [
        "# TRANSFORMACION\n",
        "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
        "cumplenFormato = ordenes.filter(ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
        "noCumplenFormato = ordenes.filter(~ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
        "print(noCumplenFormato.count(), cumplenFormato.count())\n",
        "print(noCumplenFormato.show(5))\n",
        "noCumplenFormato = noCumplenFormato.withColumn('Fecha_de_pedido', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d'), t.StringType())(f.col('Fecha_de_pedido')))\n",
        "ordenes = noCumplenFormato.union(cumplenFormato)\n",
        "noCumplenFormato.count(), ordenes.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN-fsV5_86v7"
      },
      "source": [
        "Descripciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lPrvq2m86v7"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes.where(length(col(\"Descripcion\")) <= 10).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a31mBQwD86v7"
      },
      "source": [
        "Imputar valor maximo de cantidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAeVZ5Xc86v8"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEM7tcJ986v8"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes = detallesOrdenes.replace( 10000000, 360, 'Cantidad')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmteyIwh86v8"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uda-rfmr86v8"
      },
      "outputs": [],
      "source": [
        "detallesOrdenes.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOcOg5wJ86v8"
      },
      "outputs": [],
      "source": [
        "ordenes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRyB9egF86v8"
      },
      "source": [
        "Se unen los dos dataframes en un nuevo dataframe, se verifica que no haya duplicados y si los hay se eliminan. Se crea un nuevo dataframe que va a tener toda la información del hecho orden transformada y lista para continuar el proceso de cargue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RVZ_KIj86v8"
      },
      "outputs": [],
      "source": [
        "ordenes_tmp =ordenes\n",
        "ordenes_tmp = ordenes_tmp.join(detallesOrdenes, how = 'inner', on = 'ID_de_pedido')\n",
        "ordenes_tmp = ordenes_tmp.withColumn('Valor_total',col('Precio_unitario')*col('Cantidad'))\n",
        "ordenes_tmp = ordenes_tmp.withColumn('Impuestos',col('Valor_total')*col('Tasa_de_impuesto'))\n",
        "ordenes_tmp = ordenes_tmp.selectExpr('ID_de_pedido as ID_de_pedido_T','ID_Producto','Fecha_de_pedido','ID_de_cliente','ID_de_vendedor','ID_Tipo_Paquete','Cantidad','Valor_total', 'Impuestos')\n",
        "\n",
        "print((ordenes_tmp.count(),ordenes_tmp.distinct().count()))\n",
        "\n",
        "ordenes_tmp = ordenes_tmp.drop_duplicates()\n",
        "ordenes_tmp.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgK1kASDpz8a"
      },
      "outputs": [],
      "source": [
        "guardar_db(dest_db_connection_string, ordenes_tmp,'Estudiante_i_XXXXXX.Hecho_Orden_Tmp', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1KQpgHZpz8a"
      },
      "source": [
        "Cree la tabla de Fecha según el material compartido y adicione el left join al crear la tabla de ordenes para que quede completa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbkdyMKxpz8a"
      },
      "outputs": [],
      "source": [
        "# El idPedido representa la dimensión degenerada Pedido\n",
        "# Si hay campos nulos en ordenes_tmp al hacer join por el left outer join no se perderan y se utiliza como comodín un id=0 que debe existir en todas las dimensiones.\n",
        "# Ese comodín representa el registro sin Dato.\n",
        "# Debe adicionarle a todas las tablas el registro con identificador 0, como se muestra para la tabla de clientes\n",
        "# Recuerde que falta incluir el join con la tabla de Fecha para que la tabla quede completa.\n",
        "\n",
        "ordenes = ordenes_tmp.alias('o').join(clientes.alias('cl'), ordenes_tmp.ID_de_cliente == clientes.ID_Cliente_T,'left')\\\n",
        "                    .join(ciudades.alias('ciu'), clientes.ID_CiudadEntrega == ciudades.ID_ciudad_T,'left') \\\n",
        "                    .join(empleados.alias('e'), ordenes_tmp.ID_de_vendedor == empleados.ID_Empleado_T,'left') \\\n",
        "                    .join(paquetes.alias('p'), ordenes_tmp.ID_Tipo_Paquete == paquetes.ID_TipoPaquete_T,'left') \\\n",
        "                    .join(productos.alias('pr'), (ordenes_tmp.ID_Producto == productos.ID_Producto_T) ,'left') \\\n",
        "                    .select([col('o.ID_de_pedido_T'),col('cl.ID_Cliente_DWH'),col('ciu.ID_Ciudad_DWH'),\n",
        "                             col('e.ID_Empleado_DWH'),col('pr.ID_Producto_DWH'),col('p.ID_TipoPaquete_DWH'),\n",
        "                             col('o.Cantidad'),col('o.Valor_total'),col('o.Impuestos')]) \\\n",
        "                    .fillna({'ID_Cliente_DWH': 0, 'ID_Ciudad_DWH': 0, 'ID_Empleado_DWH': 0, 'ID_Producto_DWH': 0,\n",
        "                             'ID_TipoPaquete_DWH': 0})\n",
        "ordenes.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l7U1G31pz8b"
      },
      "outputs": [],
      "source": [
        "ordenes = ordenes.select('ID_de_pedido_T','ID_Ciudad_DWH','ID_Cliente_DWH','ID_Empleado_DWH','ID_Producto_DWH',\n",
        "                         'ID_TipoPaquete_DWH','Cantidad','Impuestos','Valor_total') \\\n",
        "                    .withColumnRenamed('Valor_total','Total')\n",
        "ordenes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9f10qpB86v9"
      },
      "source": [
        "#### Carga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRd2OHVvpz8b"
      },
      "source": [
        "**OJO** Recuerde antes de guardar los datos que la tabla no exista o este vacía, para que no se guarden los mismos datos varias veces y no ocupar más espacio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrDMoAPZpz8b"
      },
      "outputs": [],
      "source": [
        "guardar_db(dest_db_connection_string, ordenes,'Estudiante_i_XXXXXX.Hecho_Orden', db_user, db_psswd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXk0Fxmu86v9"
      },
      "source": [
        "Verifique los resultados usando MySQL Workbench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWmcDXue86v9"
      },
      "source": [
        "# Resultado de consultas\n",
        "Corresponde a las consultas realizadas sobre las tablas, para mostrar el estado final de las tablas pobladas como resultado del proceso de ETL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGMlLaje86v9"
      },
      "source": [
        "# 3. Tarea ETL\n",
        "Espacio para desarrollar la tarea planteada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwyeLpt386v9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euvEeguv86v9"
      },
      "source": [
        "## 4. Cierre\n",
        "Completado este tutorial, ya sabe cómo realizar ETL básicos en PySpark.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaFNpgeW86v9"
      },
      "source": [
        "## 5. Información adicional\n",
        "\n",
        "Si quiere conocer más sobre PySpark la guía más detallada es la documentación oficial, la cual puede encontrar acá: https://spark.apache.org/docs/latest/api/python/index.html <br>\n",
        "Para ir directamente a la documentación de PySpark SQL, donde está la información sobre los DataFrames, haga clic en este enlace: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html <br>\n",
        "\n",
        "El Capítulo 2 del libro <i>Learn PySpark : Build Python-based Machine Learning and Deep Learning Models, New York: Apress. 2019</i> de Pramod Singh contiene muchos ejemplos útiles, puede encontrarlo en la biblioteca virtual de la universidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kIcwffv86v-"
      },
      "source": [
        "## 6. Preguntas frecuentes\n",
        "\n",
        "- Si al intentar escribir un <i>dataframe</i> obtiene un error en el formato:\n",
        "    ```\n",
        "    path file:<PATH>/dw/<PATH> already exists.;\n",
        "    ```\n",
        "    Borre la carpeta indicada en el error y vuelva a intentar.\n",
        "\n",
        "- Si al ejecutar su código obtiene el error:\n",
        "    ```\n",
        "    ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=tutorial ETL PySpark, master=local) created by __init__ at <ipython-input-4-64455da959dd>:92\n",
        "\n",
        "    ```\n",
        "    reinicie el kernel del notebook y vuelva a intentar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J9jYwEJ86v-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "vtE61qk986vx",
        "X9Oou0g986vy",
        "B5kFkHTD86vz",
        "ddFhEOmL86vz",
        "MuvVgJ4R86v0",
        "BZjDeVYd86v1",
        "_7xbgfCk86v1",
        "Rh_102Yy86v1",
        "HogvCqW_86v2",
        "9rKmT9jd86v2",
        "R9SnkMUH86v3",
        "k8O1GvOd86v3",
        "Mo633Vpg86v3",
        "i36NawhX86v4",
        "LvgnsPfK86v4",
        "dTv_CIOT86v5",
        "N9f10qpB86v9"
      ],
      "name": "MISW-ETL-TutorialETL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}