{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\lenovo\\appdata\\roaming\\python\\python39\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del árbol de decisión manual: 2584.577836553867\n",
      "MAE del árbol de decisión manual: 1998.9576329972087\n"
     ]
    }
   ],
   "source": [
    "# Celda 1\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Definición del árbol de decisión manual\n",
    "def decision_tree_manual(X_train, y_train, X_test):\n",
    "    # Reglas de división\n",
    "    threshold_year = 2015\n",
    "    threshold_mileage = 50000\n",
    "    \n",
    "    # Predicción para el conjunto de prueba\n",
    "    y_pred = []\n",
    "    for index, row in X_test.iterrows():\n",
    "        if row['Year'] <= threshold_year:\n",
    "            if row['Mileage'] <= threshold_mileage:\n",
    "                y_pred.append(np.mean(y_train[(X_train['Year'] <= threshold_year) & (X_train['Mileage'] <= threshold_mileage)]))\n",
    "            else:\n",
    "                y_pred.append(np.mean(y_train[(X_train['Year'] <= threshold_year) & (X_train['Mileage'] > threshold_mileage)]))\n",
    "        else:\n",
    "            if row['Mileage'] <= threshold_mileage:\n",
    "                y_pred.append(np.mean(y_train[(X_train['Year'] > threshold_year) & (X_train['Mileage'] <= threshold_mileage)]))\n",
    "            else:\n",
    "                y_pred.append(np.mean(y_train[(X_train['Year'] > threshold_year) & (X_train['Mileage'] > threshold_mileage)]))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Predicción utilizando el árbol de decisión manual\n",
    "y_pred_manual = decision_tree_manual(X_train, y_train, X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE\n",
    "rmse_manual = np.sqrt(mean_squared_error(y_test, y_pred_manual))\n",
    "mae_manual = mean_absolute_error(y_test, y_pred_manual)\n",
    "\n",
    "print(\"RMSE del árbol de decisión manual:\", rmse_manual)\n",
    "print(\"MAE del árbol de decisión manual:\", mae_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo Bagging manual: 1796.967\n",
      "MAE del modelo Bagging manual: 1338.846\n"
     ]
    }
   ],
   "source": [
    "# Celda 2\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Definición del modelo Bagging manual\n",
    "def bagging_manual(X_train, y_train, X_test, num_trees=10):\n",
    "    y_preds = []\n",
    "    \n",
    "    for _ in range(num_trees):\n",
    "        # Crear un subconjunto aleatorio del conjunto de entrenamiento (muestreo con reemplazo)\n",
    "        idx = np.random.choice(X_train.index, size=len(X_train), replace=True)\n",
    "        X_train_subset = X_train.loc[idx]\n",
    "        y_train_subset = y_train.loc[idx]\n",
    "        \n",
    "        # Entrenar un árbol de decisión en el subconjunto\n",
    "        tree = DecisionTreeRegressor(random_state=42)\n",
    "        tree.fit(X_train_subset, y_train_subset)\n",
    "        \n",
    "        # Realizar predicciones en el conjunto de prueba\n",
    "        y_pred = tree.predict(X_test)\n",
    "        y_preds.append(y_pred)\n",
    "    \n",
    "    # Promediar las predicciones de todos los árboles\n",
    "    y_pred_bagging = np.mean(y_preds, axis=0)\n",
    "    \n",
    "    return y_pred_bagging\n",
    "\n",
    "# Predicción utilizando el modelo Bagging manual\n",
    "y_pred_bagging_manual = bagging_manual(X_train, y_train, X_test, num_trees=10)\n",
    "\n",
    "# Cálculo de RMSE y MAE\n",
    "rmse_bagging_manual = np.sqrt(mean_squared_error(y_test, y_pred_bagging_manual))\n",
    "mae_bagging_manual = mean_absolute_error(y_test, y_pred_bagging_manual)\n",
    "\n",
    "#print(\"RMSE del modelo Bagging manual:\", rmse_bagging_manual)\n",
    "#print(\"MAE del modelo Bagging manual:\", mae_bagging_manual)\n",
    "print(\"RMSE del modelo Bagging manual: {:.3f}\".format(rmse_bagging_manual))\n",
    "print(\"MAE del modelo Bagging manual: {:.3f}\".format(mae_bagging_manual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo Bagging con sklearn: 1819.7321845417173\n",
      "MAE del modelo Bagging con sklearn: 1361.2664479544706\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from math import log2\n",
    "\n",
    "# Definición del modelo Bagging con la librería sklearn\n",
    "bagging_model_sklearn = BaggingRegressor(base_estimator=DecisionTreeRegressor(max_features=int(log2(X_train.shape[1]))), \n",
    "                                         n_estimators=10, \n",
    "                                         random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "bagging_model_sklearn.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred_bagging_sklearn = bagging_model_sklearn.predict(X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE\n",
    "rmse_bagging_sklearn = np.sqrt(mean_squared_error(y_test, y_pred_bagging_sklearn))\n",
    "mae_bagging_sklearn = mean_absolute_error(y_test, y_pred_bagging_sklearn)\n",
    "\n",
    "print(\"RMSE del modelo Bagging con sklearn:\", rmse_bagging_sklearn)\n",
    "print(\"MAE del modelo Bagging con sklearn:\", mae_bagging_sklearn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Randon Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo Random Forest: 1765.4118259983413\n",
      "MAE del modelo Random Forest: 1314.4207078056425\n"
     ]
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Definición del modelo Random Forest con la librería sklearn\n",
    "random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred_random_forest = random_forest_model.predict(X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE\n",
    "rmse_random_forest = np.sqrt(mean_squared_error(y_test, y_pred_random_forest))\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred_random_forest)\n",
    "\n",
    "print(\"RMSE del modelo Random Forest:\", rmse_random_forest)\n",
    "print(\"MAE del modelo Random Forest:\", mae_random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 200}\n",
      "RMSE del mejor modelo Random Forest: 1564.2461359342767\n",
      "MAE del mejor modelo Random Forest: 1147.2014922680428\n"
     ]
    }
   ],
   "source": [
    "# Celda 5\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definición del modelo Random Forest\n",
    "random_forest_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Definición de los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=random_forest_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "\n",
    "# Mejor modelo después de la búsqueda de hiperparámetros\n",
    "best_random_forest_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción en el conjunto de prueba con el mejor modelo\n",
    "y_pred_best_random_forest = best_random_forest_model.predict(X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE con el mejor modelo\n",
    "rmse_best_random_forest = np.sqrt(mean_squared_error(y_test, y_pred_best_random_forest))\n",
    "mae_best_random_forest = mean_absolute_error(y_test, y_pred_best_random_forest)\n",
    "\n",
    "print(\"RMSE del mejor modelo Random Forest:\", rmse_best_random_forest)\n",
    "print(\"MAE del mejor modelo Random Forest:\", mae_best_random_forest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE del modelo XGBoost: 1605.2355199928948\n",
      "MAE del modelo XGBoost: 1185.2272991506386\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Definición del modelo XGBoost con la librería sklearn\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción en el conjunto de prueba\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"RMSE del modelo XGBoost:\", rmse_xgb)\n",
    "print(\"MAE del modelo XGBoost:\", mae_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'colsample_bytree': 0.6, 'gamma': 0, 'learning_rate': 0.1}\n",
      "RMSE del mejor modelo XGBoost: 1543.9585735005624\n",
      "MAE del mejor modelo XGBoost: 1134.757230763072\n"
     ]
    }
   ],
   "source": [
    "# Celda 7\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definición del modelo XGBoost\n",
    "xgb_model = XGBRegressor(random_state=42)\n",
    "\n",
    "# Definición de los parámetros a ajustar\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Búsqueda de hiperparámetros con validación cruzada\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mejor combinación de parámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Mejores parámetros:\", best_params)\n",
    "\n",
    "# Mejor modelo después de la búsqueda de hiperparámetros\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicción en el conjunto de prueba con el mejor modelo\n",
    "y_pred_best_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Cálculo de RMSE y MAE con el mejor modelo\n",
    "rmse_best_xgb = np.sqrt(mean_squared_error(y_test, y_pred_best_xgb))\n",
    "mae_best_xgb = mean_absolute_error(y_test, y_pred_best_xgb)\n",
    "\n",
    "print(\"RMSE del mejor modelo XGBoost:\", rmse_best_xgb)\n",
    "print(\"MAE del mejor modelo XGBoost:\", mae_best_xgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celda 8\n",
    "Con los resultados arrojados podemos realizar la comparación y el análisis de los diferentes modelos:\n",
    "\n",
    "Análisis y comparación:\n",
    "- Mejor rendimiento (menor RMSE): El modelo XGBoost con calibración de parámetros (RMSE: 1543.96).\n",
    "- Mejor rendimiento (menor MAE): El modelo XGBoost con calibración de parámetros (MAE: 1134.76).\n",
    "\n",
    "Ventajas del mejor modelo (XGBoost con calibración de parámetros):\n",
    "- Proporciona un RMSE y MAE más bajos en comparación con otros modelos, lo que indica una mejor capacidad de predicción.\n",
    "- XGBoost tiene una capacidad de regularización incorporada y puede manejar relaciones más complejas entre las características.\n",
    "- La calibración de parámetros ayuda a ajustar el modelo para obtener el mejor rendimiento posible.\n",
    "- Desventajas del modelo con menor desempeño (Árbol de decisión manual):\n",
    "- El rendimiento del árbol de decisión manual es el peor en términos de RMSE y MAE, lo que indica que es el modelo menos preciso.\n",
    "- Los árboles de decisión manuales pueden ser propensos al sobreajuste y tienen una capacidad limitada para capturar relaciones complejas en los datos.\n",
    "- En resumen, el modelo XGBoost con calibración de parámetros muestra el mejor rendimiento en términos de precisión predictiva en este conjunto de datos específico. Proporciona resultados significativamente mejores que los otros modelos considerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Ressultado nombre modelo                    |    RMSE |     MAE |\n",
      "|:--------------------------------------------|--------:|--------:|\n",
      "| Árbol de decisión manual                    | 2584.58 | 1998.96 |\n",
      "| Bagging manual                              | 1792.6  | 1337.23 |\n",
      "| Bagging con librería (Sklearn)              | 1819.73 | 1361.27 |\n",
      "| Random Forest con librería (Sklearn)        | 1765.41 | 1314.42 |\n",
      "| Random Forest con calibración de parámetros | 1564.25 | 1147.2  |\n",
      "| XGBoost con librería (Sklearn)              | 1605.24 | 1185.23 |\n",
      "| XGBoost con calibración de parámetros       | 1543.96 | 1134.76 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Datos de los modelos\n",
    "datos_modelos = {\n",
    "    \"Árbol de decisión manual\": [2584.58, 1998.96],\n",
    "    \"Bagging manual\": [1792.60, 1337.23],\n",
    "    \"Bagging con librería (Sklearn)\": [1819.73, 1361.27],\n",
    "    \"Random Forest con librería (Sklearn)\": [1765.41, 1314.42],\n",
    "    \"Random Forest con calibración de parámetros\": [1564.25, 1147.20],\n",
    "    \"XGBoost con librería (Sklearn)\": [1605.24, 1185.23],\n",
    "    \"XGBoost con calibración de parámetros\": [1543.96, 1134.76]\n",
    "}\n",
    "\n",
    "# Convertir el diccionario en un DataFrame de Pandas\n",
    "df_modelos = pd.DataFrame.from_dict(datos_modelos, orient='index', columns=['RMSE', 'MAE'])\n",
    "\n",
    "# Agregar el encabezado \"Nombre modelo\" a la primera columna\n",
    "df_modelos.index.name = 'Ressultado nombre modelo'\n",
    "#print(df_modelos)\n",
    "print(df_modelos.to_markdown())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
